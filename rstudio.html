<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Qianyu Hang at NC State University" />


<title>Data analysis in R Studio</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Qianyu's Blog</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="stream.html">Stream Restoration</a>
    </li>
    <li>
      <a href="questions.html">Research Questions</a>
    </li>
    <li>
      <a href="field.html">Field Visit</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tutorial
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="rstudio.html">R Studio</a>
    </li>
    <li>
      <a href="rmarkdown.html">R Markdown</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Courses
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="channel.html">Open Channel Flow</a>
    </li>
  </ul>
</li>
<li>
  <a href="cv.html">CV</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    NC State
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://www.ncsu.edu/">NC State</a>
    </li>
    <li>
      <a href="https://www.lib.ncsu.edu/">Libraries</a>
    </li>
    <li>
      <a href="https://www.bae.ncsu.edu/">Bio&amp;Ag Eng</a>
    </li>
  </ul>
</li>
<li>
  <a href="us.html">US</a>
</li>
<li>
  <a href="stories.html">Stories</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-link"></span>
     
    Connect
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="mailto:qhang@ncsu.edu">
        <span class="fa fa fa fa-envelope-o"></span>
         
        email
      </a>
    </li>
    <li>
      <a href="https://scholar.google.com/citations?user=bakil3oAAAAJ&amp;hl=en">
        <span class="fa fa-google"></span>
         
        Google Scholar
      </a>
    </li>
    <li>
      <a href="https://github.com/hangqianyu">
        <span class="fa fa-github"></span>
         
        Github
      </a>
    </li>
    <li>
      <a href="https://www.linkedin.com/in/qianyu-hang-99562215a/">
        <span class="fa fa-linkedin"></span>
         
        Linkedin
      </a>
    </li>
    <li>
      <a href="https://www.researchgate.net/profile/Qianyu_Hang2">ResearchGate</a>
    </li>
  </ul>
</li>
<li>
  <a href="comments.html">Comments</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Data analysis in R Studio</h1>
<h4 class="author"><em><a href="https://github.com/hangqianyu">Qianyu Hang</a> at NC State University</em></h4>
<h4 class="date"><em>Thu May 24, 2018</em></h4>

</div>


<p><img src="images/rstudio.png" width="80%" style="display: block; margin: auto;" /></p>
<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>R is a language and environment for statistical computing and graphics. R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, …) and graphical techniques, and is highly extensible. One of R’s strengths is the ease with which well-designed publication-quality plots can be produced, including mathematical symbols and formulae where needed. The most important thing to me is it is open source and free software. While i prefer R Studio which is open source and enterprise-ready profession software for R. I think it is much more easier to use R Studio than R (You might think so as well).</p>
<p>I am not good at codeing all my life!!! NEVER! But I benefited a lot from courses in <a href="https://www.datacamp.com/home">Datacamp</a> which is recommended by Dr. Nelson and Dr. Birgand. So go there and enjoy your R Studio-ing if you are interested (maybe not for free though :-D)! At first, you will find it is very annoying to use codes and remember which function makes this and which function makes that (if not, you might be nature-born data analyst). But for now, although i am not good at it, i really enjoy coding and R Studio-ing after grasping some basic R and R Markdown knowledge. Here, i combined experience from <a href="https://www.datacamp.com/home">DataCamp</a> and myself to help you master it easier. To begin with, there are some basic programming notes you need to remember. You might want to jump right into data visualization portion, but data analysts usually spend around 80% of their time cleaning and tidying data, and only 20% of time plotting. So, let’s get it started!</p>
</div>
<div id="basic-programming-notes" class="section level1">
<h1>Basic programming notes</h1>
<pre class="r"><code>args(sd) # Useful trick for inspecting the arguments of sd() function in a quick way

Or help(sd) # works well as well

install.packages(&quot;package name&quot;) # To install a package

library(package name) # To select this package

download.file(url, destfile, ...) # in system package</code></pre>
<p>To convert the capital letter to lower case, use function <code>tolower()</code>. vise versa, <code>toupper()</code> is the opposite. Inspect our workspace with <code>dir()</code>. To summarize a vector, use <code>summary()</code> to obtain it. To traverse over a set of data like a list or vector, and calling the specified function for each item, use <code>lapply(X, FUN, ...)</code>. <code>FUN</code> means the function to be applied to each element of x. X is a vector or list or expression object.</p>
<p>Relational operators</p>
<pre><code>== - Equality
!= - Inequality
&gt; - Greater than
&lt; - Less than
&gt;= - Greater than or equal to
&lt;= - Less than or equal to
x %in% c(a, b, c), TRUE if x is in the vector c(a, b, c)</code></pre>
<p>Logical operators</p>
<pre><code>&amp; - AND
| - OR
! - NOT</code></pre>
<p>Answering the question which grades in your class are higher than 75? with a vector of logicals is not very insightful. It’s much better to ask the question how many grades in your class are higher than 75? instead. You can answer such questions with the sum() function. Each TRUE you passs count as 1, each FALSE as 0. <span style="color:red;"> Just in the same way, you can use mean(); this will give you the proportion of TRUE values in the data structure you pass it.</p>
<p><strong>else if statement</strong></p>
<pre class="r"><code>if (condition) {
  expr
} else if (condition) {
  expr
} else {
  expr
}</code></pre>
<p><strong>subsetting from dataset</strong></p>
<pre class="r"><code>subset(x, subset, ...) # subset: logical expression indicating elements or rows to keep</code></pre>
<p><strong>Useful math functions that R features:</strong></p>
<pre class="r"><code>abs() calculate the absolute value.
sum() calculate the sum of all the values in a data structure.
mean() calculate the arithmetic mean.
round() Round the values to 0 decimal places by default. Try out ?round in the console for variations of round() and ways to change the number of digits to round to</code></pre>
<p><strong>Differences between [, [[ and $</strong> Please refer to <a href="https://www.r-bloggers.com/r-accessors-explained/">Detailed explanation</a></p>
<hr />
</div>
<div id="operators" class="section level1">
<h1>Operators</h1>
<p>For the meaning of operators in R, you would like to see <a href="https://www.tutorialspoint.com/r/r_operators.htm">here</a>.</p>
<hr />
</div>
<div id="read-flatexcel-files" class="section level1">
<h1>Read flat/excel files</h1>
<p>There are several ways to do it. Basically, for “utils” package which is already existed in system library, it is east to read a table using read.table() function as below:</p>
<pre class="r"><code>read.table(&quot;states.csv&quot;, header = TRUE/FALSE, sep = &quot;,&quot;, stringsASFactors = FALSE)

read.csv(&quot;states.csv&quot;, stringsASFactors = TRUE/FALSE) # To read a csv file</code></pre>
<p>Likewise, in the “readr” package, just use functions below:</p>
<pre class="r"><code>read_csv(object, col_names = TRUE) # would be enough to import csv files

read_tsv(object) # to load txt files

read_delim(object, delim = &quot;\t&quot;, col_names = ...) # function which is the main function of the &quot;readr&quot; package. StringsASFactors do not need to be specified in all three functions as &quot;utils&quot; package required

Extra important arguments: through skip and n_max arguments, you can control which part of your flat file you&#39;re actually importing into R. skip specifies the number of lines you&#39;re ignoring in the flat file before actually starting to import data. n_max specifies the number of lines you&#39;re actually importing.</code></pre>
<p>For “data.table” package, function to import data is fread() function which is extremely perfect for lazy people. Despite the different seperators, freed() can easily read csv files without adding sep = “,/.” or delim = “,/.”.</p>
<p>For “readxl” package, there are two main functions that useed for importing excel sheets into R.</p>
<pre class="r"><code>One is excel_sheets() # to list different sheets

the other one is read_excel() # to actually import data into R. To explain the arguments in detail, see below:

read_excel(path, sheet = 1, col_names = TRUE (by default), col_types = numeric/date/NULL, skip = 0/1/2...) # to specify what excel you wanna import. If you selected Null as col_types, then that column will not be shown in final printout.</code></pre>
<p>For “gdata” package, we can utilize</p>
<pre class="r"><code>read.xls(&quot;.xls&quot;, sheet = 1/2/3... or &quot;sheet name&quot;) # to import a xls file into R</code></pre>
<p>For “XLConnect” Package, it bridges between Exccel and R. works with xls and xlsx files. Remember to use “lapply” to read all sheets automatically. XLConnect package can make it able to edit excel files from inside R, whose functions are shown below.</p>
<pre class="r"><code>loadWorkbook(filename...) # To build a connection between R and xlsx files

createSheet(object, &quot;sheet name&quot;) # To create a new sheet in excel files

readWorksheet(object, sheet = 1/2/3..., startCol = 1/2/3..., endCol = 1/2/3...) # To import selected columns to R 

writeWorksheet(object, data, sheet, ...) # load new data into new sheet created

saveWorkbook(object, file) # save the new sheet with a file name
renameSheet(object, sheet, newName) # rename a sheet

removeSheet(object, sheet) # remove sheets
getSheets(object) # to list all sheets in R

For example, lapply(getSheets(loadWorkbook(&quot;.xlsx file&quot;)), readWorksheet, object = &quot;.xlsx file&quot;)</code></pre>
<hr />
</div>
<div id="connecting-to-a-database" class="section level1">
<h1>connecting to a database</h1>
<p>The first step to import data from a SQL database is creating a connection to it. We might need different packages depending on the database you want to connect to. All of these packages do this in a uniform way, as specified in the “DBI” or “RMySQL” package. If the MySQL database is a remote database hosted on a server, you’ll also have to specify the following arguments in dbConnect(): dbname, host, port, user and password. For example,</p>
<pre class="r"><code>con &lt;- dbConnect(RMySQL::MySQL(), 
                 dbname = &quot;tweater&quot;, 
                 host = &quot;courses.csrrinzqubik.us-east-1.rds.amazonaws.com&quot;, 
                 port = 3306,
                 user = &quot;student&quot;,
                 password = &quot;datacamp&quot;)

* I do not really know what the hell is going on with database connection. Just a note for future use.</code></pre>
<p>List and import tables in the database:</p>
<pre class="r"><code>dbListTables(DBIConnection object as produced by &quot;dbConnect&quot; function) # list all tables in the database

dbReadTable(object, &quot;column/table name&quot;) # to tell R that which data you wanna import

dbDisconnect(object) #  is polite to disconnect the databases after you are done</code></pre>
<p>In your life as a data scientist, you’ll often be working with huge databases that contain tables with millions of rows. If you want to do some analyses on this data, it’s possible that you only need a fraction of this data. In this case, it’s a good idea to send SQL queries to your database, and only import the data you actually need into R. dbGetQuery() is what you need. As usual, you first pass the connection object to it. The second argument is an SQL query in the form of a character string. This example selects the age variable from the people dataset where gender equals “male”:</p>
<pre class="r"><code>dbGetQuery(con, &quot;SELECT age, name FROM people WHERE gender = or &gt; or &lt; &#39;male&#39; AND ... &gt; ...&quot;)</code></pre>
<hr />
<div id="import-data-from-the-web" class="section level3">
<h3>Import data from the web</h3>
<p>Pay attention to <a href="http://" class="uri">http://</a> and <a href="https://" class="uri">https://</a>. There is, however, a safer alternative to HTTP, namely HTTPS, which stands for HypterText Transfer Protocol Secure. Just remember this: HTTPS is relatively safe, HTTP is not. We can use the standard importing functions with <a href="https://" class="uri">https://</a> connections since R version 3.2.2</p>
<p>you can read excel files on the web using the read_excel package by first downloading the file with the download.file() function. There’s more: with download.file() you can download any kind of file from the web, using HTTP and HTTPS: images, executable files, but also .RData files. An RData file is very efficient format to store R data. You can load data from an RData file using the load() function, but this function does not accept a URL string as an argument.</p>
<pre class="r"><code>load(file, envir = parent.frame(), verbose = FALSE) # file: a readable connection or a character string giving the name of the file to load; envir: the environment where the data should be loaded; verbose: should item names be printed during loading?</code></pre>
<p>Downloading a file from the Internet means sending a GET request and receiving the file you asked for. Internally, all the previously discussed functions use a GET request to download files. “httr” package provides a convenient function, GET() to execute this GET request. The result is a response object, that provides easy access to the status code, content-type and, of course, the actual content. You can extract the content from the request using the content() function. At the time of writing, there are three ways to retrieve this content: as a raw object, as a character vector, or an R object, such as a list. If you don’t tell content() how to retrieve the content through the as argument, it’ll try its best to figure out which type is most appropriate based on the content-type.</p>
<pre class="r"><code>download.file(object, &quot;file name&quot;)

GET()

content() </code></pre>
<p>For “jsonlite” package, In the simplest setting, fromJSON() can convert character strings that represent JSON data into a nicely structured R list. Let’s take a look at an example,</p>
<pre class="r"><code># wine_json is a JSON
wine_json &lt;- &#39;{&quot;name&quot;:&quot;Chateau Migraine&quot;, &quot;year&quot;:1997, &quot;alcohol_pct&quot;:12.4, &quot;color&quot;:&quot;red&quot;, &quot;awarded&quot;:false}&#39;
# Convert wine_json into a list: wine
wine &lt;- fromJSON(wine_json)
# Print structure of wine
str(wine)</code></pre>
<p>We can also get a data frame by naming the columns:</p>
<pre class="r"><code>json2 &lt;- &#39;{&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]}&#39; # a contains 1, 2, 3; b contains 4, 5, 6
fromJSON(json2)</code></pre>
<p>Apart from converting JSON to R with fromJSON(), you can also use toJSON() to convert R data to a JSON format. In its most basic use, you simply pass this function an R object to convert to a JSON. The result is an R object of the class json, which is basically a character string representing that JSON.</p>
<pre class="r"><code>toJSON(x, ...) # x is the object to be encoded</code></pre>
<hr />
</div>
</div>
<div id="import-data-from-statistical-softwares-into-r" class="section level1">
<h1>Import data from statistical softwares into R</h1>
<p>Two packages can be useful to do this. One is “haven”, the other is “foreign” package. “haven” can deal with data from SAS, STATA and SPSS. For “haven” package</p>
<pre class="r"><code>read_sas() # to import SAS data

read_dta()
read_stata() # to import STATA data (dta or stata files)

read_spss()
read_por()
read_sav() # to import SPSS data (por or sav files)</code></pre>
<p>Subset example:</p>
<pre class="r"><code>subset(traits, Extroversion &gt; 40 &amp; Agreeableness &gt; 40) # Use &amp; to stand for &quot;and&quot;.</code></pre>
<p>You learned how to import a data file using the command read_sav(). With SPSS data files, it can also happen that some of the variables you import have the labelled class. This is done to keep all the labelling information that was originally present in the .sav and .por files. It’s advised to coerce (or change) these variables to factors or other standard R classes.</p>
<pre class="r"><code>as.factor() # to convert lable as a factor</code></pre>
<p>For “foreign” package, it offers a simple function to import and read STATA data: read.dta(). The arguments you will use most often are convert.dates, convert.factors, missing.type and convert.underscore, besides object. It’s all about correctly converting STATA data to standard R data structures. Where foreign provided read.dta() to read Stata data, there’s also read.spss() to read SPSS data files. To get a data frame, make sure to set to.data.frame = TRUE inside read.spss().</p>
<hr />
</div>
<div id="cleaning-and-tidying-data" class="section level1">
<h1>Cleaning and tidying data</h1>
<p>Understanding the structure of your data.</p>
<p>First, view its class by class(); Second, view its dimensions by dim(). Third, look at column names by names(). Fourth, to summarize data by summary(). Like str() function, we use the dplyr package to view structure of object as well.</p>
<pre class="r"><code>glimpse(object)</code></pre>
<p>View the top (top six rows) by head(object, n = …) function, n means how many rows you wanna show in R. While tail(object, n = …) is to show the last six rows (by default) you wanna print out.</p>
<hr />
<div id="visualizing-your-data" class="section level2">
<h2>Visualizing your data</h2>
<pre class="r"><code>hist(object) # to view histogram plot of a single variable

plot(x, y) # to view plot of two variables</code></pre>
<p>Principles of tidy data: observations as rows, variables/attributes as columns. Remember that column headers are values, not variable names.</p>
<p>For “tydyr” package,</p>
<pre class="r"><code>gather(data, key, value, -...) # data: a data frame; key: bare name of new key column; value: bare name of new value column or changed column in other words; -...: bare names of columns to not gather or change
mbta4 &lt;- gather(mbta3, &quot;month&quot;, &quot;thou_riders&quot;, -mode) # example

spread(data, key, value) # is the opposite of gather() function. key: bare name of column containing keys; value: bare name of column containing values

seperate(data, col, into) # data: a data frame; col: bare name of column to seperate; into: character vector of new column names (probably use a c() function to form a vector)

unite(data, col, ..., sep = &quot;...&quot;) # is the opposite of seperate() function. data: a data frame; col: bare name of new column; ...: bare names of columns to unite (don&#39;t need a c() function, just use comma), sep: seperator used between tow joined columns</code></pre>
<p>For more information about <code>tidyr</code> package, please refer to <a href="https://www.cnblogs.com/nxld/p/6060533.html">here</a></p>
<ul>
<li>Removing redundant info</li>
</ul>
<pre class="r"><code>my_df[1:5, ] # First 5 rows of my_df
my_df[, 4]   # Fourth column of my_df

my_df[-(1:5), ] # Omit first 5 rows of my_df
my_df[, -4]     # Omit fourth column of my_df</code></pre>
<hr />
</div>
<div id="type-conversions" class="section level2">
<h2>Type conversions</h2>
<p>It is often necessary to change, or coerce, the way that variables in a dataset are stored. This could be because of the way they were read into R (with read.csv(), for example) or perhaps the function you are using to analyze the data requires variables to be coded a certain way. Only certain coercions are allowed, but the rules for what works are generally pretty intuitive. For example, trying to convert a character string to a number gives an error: as.numeric(“some text”). There are a few less intuitive results. For example, under the hood, the logical values TRUE and FALSE are coded as 1 and 0, respectively. Therefore, as.logical(1) returns TRUE and as.numeric(TRUE) returns 1.</p>
<pre class="r"><code>as.character(...)
as.factor(...)
as.integer(...)
as.numeric(...)
as.logical(...)</code></pre>
<p>Dates can be a challenge to work with in any programming language, but thanks to the lubridate package, working with dates in R isn’t so bad. Since this course is about cleaning data, we only cover the most basic functions from lubridate to help us standardize the format of dates and times in our data.</p>
<p>As you saw in the video, these functions combine the letters y, m, d, h, m, s, which stand for year, month, day, hour, minute, and second, respectively. The order of the letters in the function should match the order of the date/time you are attempting to read in, although not all combinations are valid. Notice that the functions are “smart” in that they are capable of parsing multiple formats.</p>
<pre><code>. ymd()
. ymd_hms()
. ...just ?ymd or ?ymd_hms, you will find out which function you want.</code></pre>
</div>
<div id="string-manipulation-stringr-package" class="section level2">
<h2>String manipulation (“stringr” package)</h2>
<p>There are four key functions in stringr for cleaning data:</p>
<pre><code>-str_trim() - Trim leading and trailing white space
-str_pad - Pad with additional characters
-str_detect() - Detect a pattern
-str_replace() - Find and replace a pattern</code></pre>
<p>One common issue that comes up when cleaning data is the need to remove leading and/or trailing white space. The str_trim() function from stringr makes it easy to do this while leaving intact the part of the string that you actually want.</p>
<pre class="r"><code>str_trim(&quot;   this is a test     &quot;) # it would print out &quot;this is a test&quot;. very easy, huh?</code></pre>
<p>A similar issue is when you need to pad strings to make them a certain number of characters wide. One example is if you had a bunch of employee ID numbers, some of which begin with one or more zeros. When reading these data in, you find that the leading zeros have been dropped somewhere along the way (probably because the variable was thought to be numeric and in that case, leading zeros would be unnecessary.)</p>
<pre class="r"><code>str_pad(&quot;24493&quot;, width = 7, side = &quot;left&quot;, pad = &quot;0&quot;)
[1] &quot;0024493&quot;</code></pre>
<p>The stringr package provides two functions that are very useful for finding and/or replacing strings: str_detect() and str_replace(). Like all functions in stringr, the first argument of each is the string of interest. The second argument of each is the pattern of interest. In the case of str_detect(), this is the pattern we are searching for. In the case of str_replace(), this is the pattern we want to replace. Finally, str_replace() has a third argument, which is the string to replace with.</p>
<pre class="r"><code>str_detect(string, pattern) # string: input string; pattern: pattern to look for.

str_replace(string, pattern, replacement) # replacement: a character vector of replacements.</code></pre>
<hr />
</div>
<div id="finding-and-dealing-with-missing-values" class="section level2">
<h2>Finding and dealing with missing values</h2>
<p>As you’ve seen, missing values in R should be represented by NA, but unfortunately you will not always be so lucky. Before you can deal with missing values, you have to find them in the data. If missing values are properly coded as NA, the is.na() function will help you find them. Otherwise, if your dataset is too big to just look at the whole thing, you may need to try searching for some of the usual suspects like “”, “#N/A”, etc. You can also use the summary() and table() functions to turn up unexpected values in your data.</p>
<pre class="r"><code>is.na(x) # an R object to be tested.

any(is.na(x)) # to identify whether there is any NA in the dataset.

sum(is.na(x)) # to count number of TRUEs

which(is.na(x)) # to find indices of missing values. very useful to replace data in the dataset</code></pre>
<p>Missing values can be a rather complex subject, but here we’ll only look at the simple case where you are simply interested in normalizing and/or removing all missing values from your data. For more information on why this is not always the best strategy, search online for “missing not at random.”</p>
<pre class="r"><code>complete.cases(object, ...) # to see which rows have no missing values

na.omit(object, ...) # to remove all rows with any missing values</code></pre>
</div>
<div id="identifying-outliers-and-obvious-errors" class="section level2">
<h2>Identifying outliers and obvious errors</h2>
<p>summary() and hist() are most useful functions to identify outliers. Another useful way of looking at strange values is with boxplots boxplot(). Simply put, boxplots draw a box around the middle 50% of values for a given variable, with a bolded horizontal line drawn at the median. Values that fall far from the bulk of the data points (i.e. outliers) are denoted by open circles.</p>
<p>There are a number of stylistic conventions in the R language. Depending on who you ask, these conventions may vary. Because the period (.) has special meaning in certain situations, we generally recommend using underscores (_) to separate words in variable names. We also prefer all lowercase letters so that no one has to remember which letters are uppercase or lowercase.</p>
</div>
<div id="dplyr-package" class="section level2">
<h2>dplyr package</h2>
<p>a <strong>tbl</strong> (pronounced tibble) is just a special kind of data.frame. They make your data easier to look at, but also easier to work with. On top of this, it is straightforward to derive a tbl from a data.frame structure using <strong>tbl_df()</strong>.</p>
<p>Notes: Modifying data with lookup tables. Please refer to <a href="https://nicercode.github.io/">Nice R Code</a>.</p>
<p>The dplyr package contains five key data manipulation functions, also called verbs:</p>
<pre class="r"><code>select(df, var1, var2...) # which returns a subset of the columns,
filter(tbl, logical test) # that is able to return a subset of the rows,
arrange(tbl, column name) # that reorders the rows according to single or multiple variables,
mutate(tbl, new column name = r expression that calculate the new variable) # used to add columns from existing data, not establish a completely new, for example, if you have length, width and height variables, you can add a volume variable in the tbl by length * width * height.
summarise() # which reduces each group to a single row by calculating aggregate measures.</code></pre>
<p>Anyhow, dplyr comes with a set of helper functions that can help you select groups of variables inside a select() call:</p>
<pre class="r"><code>starts_with(&quot;X&quot;) # every name that starts with &quot;X&quot;,
ends_with(&quot;X&quot;) # every name that ends with &quot;X&quot;,
contains(&quot;X&quot;) # every name that contains &quot;X&quot;,
matches(&quot;X&quot;) # every name that matches &quot;X&quot;, where &quot;X&quot; can be a regular expression,
num_range(&quot;x&quot;, 1:5) # the variables named x01, x02, x03, x04 and x05,
one_of(x) # every name that appears in x, which should be a character vector.</code></pre>
<p><strong>Pay attention here</strong>: When you refer to columns directly inside select(), you don’t use quotes. If you use the helper functions, you do use quotes.</p>
<p>With lapply(), you could use <code>[[</code> to select specific elements from your list. The same thing is true for sapply()! Once you know about vapply(), there’s really no reason to use sapply() anymore. If the output that lapply() would generate can be simplified to an array, you’ll want to use vapply() to do this securely. If simplification is not possible, simply stick to lapply().</p>
<p>The droplevels() function removes unused levels of factor variables from your dataset. As you saw in the video, it’s often useful to determine which levels are unused (i.e. contain zero values) with the table() function.</p>
<p>load data by data() function in dplyr package. use group_by() function to <a href="https://blog.csdn.net/qq_28219759/article/details/52963773">group indexes together</a>.</p>
</div>
<div id="sampling-from-dataset" class="section level2">
<h2>Sampling from dataset</h2>
<p><strong>Simple random sample in R</strong></p>
<pre class="r"><code># Simple random sample
states_srs &lt;- us_regions %&gt;%
  sample_n(8)

# Count states by region
states_srs %&gt;%
  group_by(region) %&gt;%
  count()</code></pre>
<p><strong>Stratufied sample in R</strong></p>
<pre class="r"><code># Stratified sample
states_str &lt;- us_regions %&gt;%
  group_by(region) %&gt;%
  sample_n(2)

# Count states by region
states_str %&gt;%
  group_by(region) %&gt;%
  count()</code></pre>
<p><strong>Principles of experimental design</strong> Control: compare treatment of interest to a control group Randomize: randomly assign subjects to treatments Replicate: collect a sufficiently large sample within a study, or replicate the entire study Block: account for the potential effect of confounding variables - group subjects into blocks based on these variables - randomize within each block to treatment groups</p>
<p>The difference between numerical and categorical type is show at <a href="https://www.zhihu.com/question/41484616?sort=created">here</a></p>
<p><strong>Conditional proportions</strong> The following code generates tables of joint and conditional proportions, respectively:</p>
<pre class="r"><code>tab &lt;- table(comics$align, comics$gender)
options(scipen = 999, digits = 3) # Print fewer digits
prop.table(tab)     # Joint proportions
prop.table(tab, 2)  # Conditional on columns, make column add to 1</code></pre>
<hr />
</div>
</div>
<div id="intro-to-statistics-with-r" class="section level1">
<h1>Intro to Statistics with R</h1>
<div id="binwidth" class="section level2">
<h2>Binwidth</h2>
<pre class="r"><code># Create hist of horsepwr with binwidth of 3
cars %&gt;%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 3) +
  ggtitle(&quot;binwidth = 3&quot;)
# Create hist of horsepwr with binwidth of 30
cars %&gt;% 
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 30) +
  ggtitle(&quot;binwidth = 30&quot;)
# Create hist of horsepwr with binwidth of 60
cars %&gt;%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 60) +
  ggtitle(&quot;binwidth = 60&quot;)</code></pre>
<p><img src="images/binwidth1.png" width="50%" /><img src="images/binwidth2.png" width="50%" /><img src="images/binwidth3.png" width="50%" /></p>
<pre class="r"><code># Compute groupwise measures of spread
gap2007 %&gt;%
  group_by(continent) %&gt;%
  summarize(sd(lifeExp),
            IQR(lifeExp),
            n())

# Generate overlaid density plots
gap2007 %&gt;%
  ggplot(aes(x = lifeExp, fill = continent)) +
  geom_density(alpha = 0.3)</code></pre>
<p><img src="images/another21.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Highly skewed distributions can make it very difficult to learn anything from a visualization. Transformations can be helpful in revealing the more subtle structure.</p>
<pre class="r"><code># Create density plot of old variable
gap2007 %&gt;%
  ggplot(aes(x = pop)) +
  geom_density()
# Transform the skewed pop variable
gap2007 &lt;- gap2007 %&gt;%
  mutate(log_pop = log(pop))
# Create density plot of new variable
gap2007 %&gt;%
  ggplot(aes(x = log_pop)) +
  geom_density()</code></pre>
<p><img src="images/skewed1.png" width="50%" /><img src="images/skewed2.png" width="50%" /></p>
</div>
<div id="identify-outliers" class="section level2">
<h2>Identify Outliers</h2>
<pre class="r"><code># Filter for Asia, add column indicating outliers
gap_asia &lt;- gap2007 %&gt;%
  filter(continent == &quot;Asia&quot;) %&gt;%
  mutate(is_outlier = lifeExp &lt; 50)
# Remove outliers, create box plot of lifeExp
gap_asia %&gt;% 
  filter(!is_outlier) %&gt;%
  ggplot(aes(x = 1, y = lifeExp)) +
  geom_boxplot()</code></pre>
<p><img src="images/outliers1.png" width="50%" /><img src="images/outliers2.png" width="50%" /></p>
<pre class="reval"><code># Alternative plot: side-by-side box plots
email %&gt;%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %&gt;% # change log(0) which is -Inf to the quantity inside the log()
  ggplot(aes(x = 1, y = log_exclaim_mess)) +
  geom_boxplot() +
  facet_wrap(~ spam)
# Alternative plot: Overlaid density plots
email %&gt;%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %&gt;%
  ggplot(aes(x = log_exclaim_mess, fill = spam)) +
  geom_density(alpha = 0.3)</code></pre>
<p><img src="images/spam1.png" width="50%" /><img src="images/spam2.png" width="50%" /></p>
<p><strong>Boxplots as discretized/conditioned scatterplots</strong></p>
<pre class="r"><code>ggplot(data = ncbirths, 
       aes(x = cut(weeks, breaks = 5), y = weight)) + 
  geom_boxplot()</code></pre>
<p><img src="images/another22.png" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>Transformation</strong></p>
<pre class="r"><code># Scatterplot with coord_trans()
ggplot(data = mammals, aes(x = BodyWt, y = BrainWt)) +
  geom_point() + 
  coord_trans(x = &quot;log10&quot;, y = &quot;log10&quot;)
# Scatterplot with scale_x_log10() and scale_y_log10()
ggplot(data = mammals, aes(x = BodyWt, y = BrainWt)) +
  geom_point() +
  scale_x_log10() + scale_y_log10()</code></pre>
<p><img src="images/transformation1.png" width="50%" /><img src="images/transformation2.png" width="50%" /></p>
</div>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<p>The <code>cor(x, y)</code> function will compute the Pearson product-moment correlation between variables, x and y. Since this quantity is symmetric with respect to x and y, it doesn’t matter in which order you put the variables. At the same time, the <code>cor()</code> function is very conservative when it encounters missing data (e.g. NAs). The use argument allows you to override the default behavior of returning NA whenever any of the values encountered is NA. Setting the use argument to “pairwise.complete.obs” allows <code>cor()</code> to compute the correlation coefficient for those observations where the values of x and y are both not missing. <a href="http://bbs.pinggu.org/thread-3675473-1-1.html">This website</a> gives a detailed introduction to <code>cor()</code> function.</p>
<p>By the way, <code>group_by()</code> function has always been used in R. It might be easier for you to understand the function if you take a look at an example <a href="https://blog.csdn.net/hao1066821456/article/details/69556644">here</a>.</p>
</div>
<div id="fitting-a-linear-model-by-hand" class="section level2">
<h2>Fitting a linear model “by hand”</h2>
<p>Recall the simple linear regression model:</p>
<p>Y = b0 + b1 * X</p>
<p>Two facts enable you to compute the slope b1 and intercept b0 of a simple linear regression model from some basic summary statistics. First, the slope can be defined as:</p>
<p>b1 = r(X,Y) * sY / sX where r(X,Y) represents the correlation (cor()) of X and Y and sX and sY represent the standard deviation (sd()) of X and Y, respectively.</p>
<p>Second, the point (x¯,y¯) is always on the least squares regression line, where x¯ and y¯ denote the average of x and y, respectively.</p>
<p><strong>Fitting simple linear models</strong></p>
<p>An <code>lm()</code> object contains a host of information about the regression model that you fit. There are various ways of extracting different pieces of information. The <code>oef()</code> function displays only the values of the coefficients. Conversely, the <code>summary()</code> function displays not only that information, but a bunch of other information, including the associated standard error and p-value for each coefficient, the R2, adjusted R2, and the residual standard error.</p>
<pre class="r"><code>mod &lt;- lm(wgt ~ hgt, data = bdims)
# Show the coefficients
coef(mod)
# Show the full output
summary(mod)</code></pre>
<p>The <code>augment()</code> function from the <code>broom</code> package can tidy linear model. It takes a model object as an argument and returns a data frame that contains the data on which the model was fit, along with several quantities specific to the regression model, including the fitted values, residuals, leverage scores, and standardized residuals.</p>
<p>A traditional way to return the fitted values (i.e. the y^’s) is to run the <code>predict()</code> function on the model object. This will return a vector of the fitted values. Note that <code>predict()</code> will take an optional newdata argument that will allow you to make predictions for observations that are not in the original data.</p>
<p>A newer alternative is the <code>augment()</code> function from the broom package, which returns a data.frame with the response varible (y), the relevant explanatory variables (the x’s), the fitted value (y^) and some information about the residuals (e). <code>augment()</code> will also take a newdata argument that allows you to make predictions.</p>
<p><strong>Adding a regression line to a plot manually</strong></p>
<pre class="r"><code># Add the line to the scatterplot
ggplot(data = bdims, aes(x = hgt, y = wgt)) + 
  geom_point() + 
  geom_abline(data = coefs, 
              aes(intercept = `(Intercept)`, slope = hgt),  
              color = &quot;dodgerblue&quot;)</code></pre>
<p><img src="images/another23.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="assessing-model-fit" class="section level2">
<h2>Assessing model fit</h2>
<p>Calculate the stanard error of residuals/RMSE (Root mean squared error).</p>
<pre class="r"><code># Compute the mean of the residuals
mean(residuals(mod))
# Compute RMSE
sqrt(sum(residuals(mod)^2) / df.residual(mod))</code></pre>
<p><strong>Leverage</strong></p>
<p>The leverage of an observation in a regression model is defined entirely in terms of the distance of that observation from the mean of the explanatory variable. That is, observations close to the mean of the explanatory variable have low leverage, while observations far from the mean of the explanatory variable have high leverage. Points of high leverage may or may not be influential. The influence of an observation depends not only on its leverage, but also on the magnitude of its residual. Recall that while leverage only takes into account the explanatory variable (x), the residual depends on the response variable (y) and the fitted value (y^).</p>
<pre class="r"><code># Augment the model
augmented_mod &lt;- augment(mod)
glimpse(augmented_mod)
# scatterplot, with color
data_space &lt;- ggplot(augmented_mod, aes(x = wheels, y = totalPr, color = cond)) + 
  geom_point()
# single call to geom_line()
data_space + 
  geom_line(aes(y = .fitted))</code></pre>
<div id="r-squared-vs.adjusted-r-squared" class="section level3">
<h3>R-squared vs. adjusted R-squared</h3>
<p>Here is a website about <a href="https://blog.csdn.net/l18930738887/article/details/50629409">indexes intro</a> which is pretty helpful.</p>
<p>For interaction plot,</p>
<pre class="r"><code># interaction plot
ggplot(mario_kart, aes(y = totalPr, x = duration, color = cond)) + 
  geom_point() + 
  geom_smooth(method = &quot;lm&quot;, se = FALSE)</code></pre>
<p><img src="images/another24.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>slr &lt;- ggplot(mario_kart, aes(y = totalPr, x = duration)) + 
  geom_point() + 
  geom_smooth(method = &quot;lm&quot;, se = 0)
# model with one slope
lm(totalPr ~ duration, data = mario_kart)
# plot with two slopes
slr + aes(color = cond)</code></pre>
<p><img src="images/another25.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="models-in-3d" class="section level2">
<h2>Models in 3D</h2>
<p>An alternative way to visualize a multiple regression model with two numeric explanatory variables is as a plane in three dimensions. This is possible in R using the <code>plotly</code> package.</p>
<p>Much like <code>ggplot()</code>, the <code>plot_ly()</code> function will allow you to create a plot object with variables mapped to <code>x</code>, <code>y</code>, and <code>z</code> aesthetics. The <code>add_markers()</code> function is similar to <code>geom_point()</code> in that it allows you to add points to your 3D plot. Note that <code>plot_ly</code> uses the pipe (<code>%&gt;%</code>) operator to chain commands together.</p>
<pre class="r"><code># draw the 3D scatterplot
p &lt;- plot_ly(data = mario_kart, z = ~totalPr, x = ~duration, y = ~startPr, opacity = 0.6) %&gt;%
  add_markers() 
# draw the plane
p %&gt;%
  add_surface(x = ~x, y = ~y, z = ~plane, showscale = FALSE)</code></pre>
<p><img src="images/another26.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># draw the 3D scatterplot
p &lt;- plot_ly(data = mario_kart, z = ~totalPr, x = ~duration, y = ~startPr, opacity = 0.6) %&gt;%
  add_markers(color = ~cond) 
# draw two planes
p %&gt;%
  add_surface(x = ~x, y = ~y, z = ~plane0, showscale = FALSE) %&gt;%
  add_surface(x = ~x, y = ~y, z = ~plane1, showscale = FALSE)</code></pre>
<p><img src="images/another27.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="ggplot2-visualization" class="section level1">
<h1><code>ggplot2</code> Visualization</h1>
<p>An awesome website was recommended to you <a href="http://ggplot2.tidyverse.org/index.html">ggplot2</a></p>
<ul>
<li>Limitations of base plot functions
<ul>
<li>Plot does not get redrawn</li>
<li>Plot is drawn as an image</li>
<li>Need to manually add legend</li>
<li>No unified framework for plotting</li>
</ul></li>
<li>All Grammatical Elements:
<ul>
<li>Data, the dataset being plotted</li>
<li>Aesthetics, the scales onto which we map our data</li>
<li>Geometries, the visual elements used for our data</li>
<li>Facets, plotting small multiples</li>
<li>Statistics, representations of our data to aid understanding</li>
<li>Coordinates, the space on which the data will be plotted</li>
<li>Themes, all non-data ink</li>
</ul></li>
<li>Typical Aesthetics
<ul>
<li>x, X axis position</li>
<li>y, y axis position</li>
<li>colour, colour of dots, outlines of other shapes</li>
<li>fill, fill colour</li>
<li>size, diameter of points, thickness of lines</li>
<li>alpha, transparency</li>
<li>linetype, line dash pattern</li>
<li>labels, text on a plot or axes</li>
<li>shape, shape</li>
</ul></li>
</ul>
<p><img src="images/shape.png" width="60%" style="display: block; margin: auto;" /></p>
<pre><code>##   Aesthetic                              Description
## 1         x                          X axis position
## 2         y                          Y axis position
## 3    colour Colour of dots, outlines of other shapes
## 4      fill                              Fill colour
## 5      size   Diameter of points, thickness of lines
## 6     alpha                             Transparency
## 7  linetype                        Line dash pattern
## 8    labels                   Text on a plot or axes
## 9     shape                                    Shape</code></pre>
<pre class="r"><code>ggplot(mtcars, aes(x = cyl, y = mpg, col = disp, size = disp, shape = categorical column, shape = 1, size = 4)) + 
  geom_point(alpha = 0.4, position = &quot;jitter&quot;) + # alpha means the transparency of discrete points, 0-1, jitter expands the points more evenly, or you can just use geom_jitter()
  geom_smooth(aes(group = 1), method = &quot;lm&quot;, se = FALSE) # if you do not want any error shading, you can set se = FALSE, lm means lineal model method in scatter plot, group = 1 tells ggplot to draw a single linear model through all the points in different colors.</code></pre>
<p>Note that you can also call <code>aes()</code> within the <code>geom_point()</code> function. Which shape to use? The default geom_point() uses shape = 19 (a solid circle with an outline the same colour as the inside). Good alternatives are shape = 1 (hollow) and shape = 16 (solid, no outline). These all use the col aesthetic (don’t forget to set alpha for solid points). A really nice alternative is shape = 21 which allows you to use both fill for the inside and col for the outline! This is a great little trick for when you want to map two aesthetics to a dot.</p>
<pre class="r"><code>ggplot(mtcars, aes(x = wt, y = mpg, fill = cyl, col = am, shape = 21, size = 4, label = cyl)) +
  geom_point(alpha = 0.6) +
  geom_text()</code></pre>
<p>This time you’ll use these arguments to set attributes of the plot, not aesthetics. However, there are some pitfalls you’ll have to watch out for: these attributes can overwrite the aesthetics of your plot! <strong>A word about shapes:</strong> In the exercise “All about aesthetics, part 2”, you saw that shape = 21 results in a point that has a fill and an outline. Shapes in R can have a value from 1-25. Shapes 1-20 can only accept a color aesthetic, but shapes 21-25 have both a color and a fill aesthetic.</p>
<pre class="r"><code>ggplot(mtcars, aes(x=wt, y=mpg, col=cyl)) +
geom_point(col = my_color)
# The col setting in geom_point can overwrite the aesthetics of plot</code></pre>
<p><strong>A word about hexadecimal colours</strong>: Hexadecimal, literally “related to 16”, is a base-16 alphanumeric counting system. Individual values come from the ranges 0-9 and A-F. This means there are 256 possible two-digit values (i.e. 00 - FF). Hexadecimal colours use this system to specify a six-digit code for Red, Green and Blue values (“#RRGGBB”) of a colour (i.e. Pure blue: “#0000FF”, black: “#000000”, white: “#FFFFFF”). R can accept hex codes as valid colours.</p>
<pre class="r"><code>ggplot(mtcars, aes(x = wt, y = mpg, fill = cyl)) +
geom_text(rownames(mtcars), col = &quot;red&quot;)
# Remember specify characters with quotation makrs</code></pre>
<pre class="r"><code>val = c(&quot;#E41A1C&quot;, &quot;#377EB8&quot;)
lab = c(&quot;Manual&quot;, &quot;Automatic&quot;)
cyl.am +
  geom_bar(position = &quot;dodge&quot;) +
  scale_x_discrete(&quot;Cylinders&quot;) + 
  scale_y_continuous(&quot;Number&quot;) +
  scale_fill_manual(&quot;Transmission&quot;, 
                    values = val,
                    labels = lab)</code></pre>
<p><strong>Explaination to the code above:</strong> <code>scale_x_discrete()</code> takes as its only argument the x-axis label: “Cylinders”. <code>scale_y_continuous()</code> takes as its only argument the y-axis label: “Number”. <code>scale_fill_manual()</code> fixes the legend. The first argument is the title of the legend: “Transmission”. Next, values and labels are set to predefined values for you. These are the colors and the labels in the legend. The result of above code will be like this:</p>
<p><img src="images/bar1.png" width="70%" style="display: block; margin: auto;" /></p>
<hr />
<p>To make a univariable plot with <code>ggplot2</code>, we can set y = o in aesthetics. So far you’ve focused on scatter plots since they are intuitive, easily understood and very common. A major consideration in any scatter plot is dealing with overplotting. You’ll encounter this topic again in the geometries layer, but you can already make some adjustments here.</p>
<ul>
<li>You’ll have to deal with overplotting when you have:
<ul>
<li>Large datasets,</li>
<li>Imprecise data and so points are not clearly separated on your plot (you saw this in the video with the iris dataset),</li>
<li>Interval data (i.e. data appears at fixed values), or</li>
<li>Aligned data values on a single axis.</li>
<li>Large datasets</li>
<li>Aligned data values on a single axis</li>
</ul></li>
</ul>
<p>One very common technique that I’d recommend to always use when you have solid shapes it to use alpha blending (i.e. adding transparency). An alternative is to use hollow shapes. These are adjustments to make before even worrying about positioning.</p>
<pre class="r"><code>ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) +
geom_point(size = 4, shape = 1, alpha = 0.6)
# shape = 1 will change points to hollow points which is good, alpha can improve the overplotting</code></pre>
<p>The plot will be like:</p>
<p><img src="images/overplotting.png" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>37 Geometries in ggplot2</strong></p>
<ul>
<li>abline (scatter plot)</li>
<li>area</li>
<li>bar (bar plot)</li>
<li>bin2d</li>
<li>blank</li>
<li>boxplot</li>
<li>contour</li>
<li>crossbar</li>
<li>density</li>
<li>density2d</li>
<li>dotplot</li>
<li>errorbar (bar plot)</li>
<li>errorbarh</li>
<li>freqpoly</li>
<li>hex</li>
<li>histogram (bar plot)</li>
<li>hline</li>
<li>jitter (scatter plot)</li>
<li>line (line plot)</li>
<li>linerange</li>
<li>map</li>
<li>path</li>
<li>point (scatter plot)
<ul>
<li>Essential: x, y</li>
<li>Optional: alpha, colour, fill, shape, size</li>
</ul></li>
<li>pointrange</li>
<li>polygon</li>
<li>quantile</li>
<li>raster</li>
<li>rect</li>
<li>ribbon</li>
<li>rug</li>
<li>segment</li>
<li>smooth</li>
<li>step</li>
<li>text</li>
<li>tile</li>
<li>violin</li>
<li>vline</li>
</ul>
<pre class="r"><code># 1 - Define posn_d with position_dodge()
posn_d &lt;- position_dodge(width = 0.2)
# 2 - Use posn_d as position and adjust alpha to 0.6
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar(position = posn_d, alpha = 0.6)</code></pre>
<p>Result would be like:</p>
<p><img src="images/bar2.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(mtcars, aes(mpg, col = cyl)) +
  geom_freqpoly(binwidth = 1, position = &quot;identity&quot;)</code></pre>
<p><img src="images/freqpoly.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Add the recess periods
ggplot(economics, aes(x = date, y = unemploy/pop)) +
  geom_rect(data = recess,
         aes(xmin = begin, xmax = end, ymin = -Inf, ymax = +Inf),
         inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.2) +
  geom_line()</code></pre>
<p><img src="images/line1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Make it easy to read
ggplot(ChickWeight, aes(x = Time, y = weight, col = Diet)) +
  geom_line(aes(group = Chick), alpha = 0.3) +
  geom_smooth(lwd = 2, se = FALSE)</code></pre>
<p><img src="images/line2.png" width="70%" style="display: block; margin: auto;" /></p>
<p>While <code>qplot()</code> can do some easy plots like that:</p>
<pre class="r"><code># qplot() with geom set to jitter manually
qplot(factor(cyl), factor(vs), data = mtcars, geom = &quot;jitter&quot;)</code></pre>
<p><img src="images/qplot1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># &quot;True&quot; dot plot, with geom_dotplot():
ggplot(mtcars, aes(cyl, wt, fill = am)) +
  geom_dotplot(binaxis = &quot;y&quot;, stackdir = &quot;center&quot;)</code></pre>
<p><img src="images/dotplot1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># add facet_grid() layer
ggplot(titanic, aes(x = Pclass, fill = Sex)) +
  geom_bar(position = &quot;dodge&quot;) +
  facet_grid(. ~ Survived)
# Define an object for position jitterdodge, to use below
posn.jd &lt;- position_jitterdodge(0.5, 0, 0.6)
# but use the position object defined above
ggplot(titanic, aes(x = Pclass, y = Age, color = Sex)) +
  geom_point(size = 3, alpha = 0.5, position = posn.jd) +
  facet_grid(. ~ Survived)</code></pre>
<p>Two figures are compared:</p>
<p><img src="images/jitter1.png" width="50%" /><img src="images/jitter2.png" width="50%" /></p>
</div>
<div id="advanced-plotting-with-ggplot2" class="section level1">
<h1>Advanced plotting with <code>ggplot2</code></h1>
<p><img src="images/stat_functions.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;, se = FALSE)

# 2 - Plot 1, plus another stat_smooth() containing a nested aes()
ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;, se = FALSE) +
  stat_smooth(method = &quot;lm&quot;, se = FALSE, aes(group = 1))</code></pre>
<p><img src="images/smooth1.png" width="50%" /><img src="images/smooth2.png" width="50%" /></p>
<p>In the previous exercise we used <code>se = FALSE</code> in <code>stat_smooth()</code> to remove the 95% Confidence Interval. Here we’ll consider another argument, <code>span</code>, used in LOESS smoothing, and we’ll take a look at a nice scenario of properly mapping different models.</p>
<pre class="r"><code>ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;, se = FALSE) +
  stat_smooth(method = &quot;loess&quot;, aes(group = 1),
              se = FALSE, col = &quot;black&quot;, span = 0.7)

# Set col to &quot;All&quot;, inside the aes layer of stat_smooth()
ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;, se = FALSE) +
  stat_smooth(method = &quot;loess&quot;,
              # Add col inside aes()
              aes(group = 1, col = &quot;All&quot;),
              # Remove the col argument below
              se = FALSE, span = 0.7)

# Add scale_color_manual to change the colors
myColors &lt;- c(brewer.pal(3, &quot;Dark2&quot;), &quot;black&quot;)
ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) +
  geom_point() +
  stat_smooth(method = &quot;lm&quot;, se = FALSE, span = 0.7) +
  stat_smooth(method = &quot;loess&quot;, 
              aes(group = 1, col=&quot;All&quot;), 
              se = FALSE, span = 0.7) +
  scale_color_manual(&quot;Cylinders&quot;, values = myColors)</code></pre>
<p><img src="images/multi1.png" width="50%" /><img src="images/multi2.png" width="50%" /><img src="images/multi3.png" width="50%" /></p>
<p>Focus on the color because <code>scale_color_brewer</code> on default have a maximum 9 for palette Blues.</p>
<pre class="r"><code>ggplot(Vocab, aes(x = education, y = vocabulary, col = factor(year))) +
  stat_smooth(method = &quot;lm&quot;, se = FALSE) +  # smooth
  scale_color_brewer()  # colors

# Plot 5: Add the group aes, specify alpha and size
ggplot(Vocab, aes(x = education, y = vocabulary, col = year, group = factor(year))) +
  stat_smooth(method = &quot;lm&quot;, se = FALSE, alpha = 2, size = 2) +
  scale_color_gradientn(colors = brewer.pal(9, &quot;YlOrRd&quot;))</code></pre>
<p><img src="images/color1.png" width="50%" /><img src="images/color2.png" width="50%" /></p>
<p>Another useful stat function is <code>stat_sum()</code>. This function calculates the total number of overlapping observations and is another good alternative to overplotting.</p>
<pre class="r"><code># Jittering only
p &lt;- ggplot(Vocab, aes(x = education, y = vocabulary)) +
  geom_jitter(alpha = 0.2)
# Add stat_sum will map overall count of each dot onto size
p +
  stat_sum()
# Set size range of the dots
p +
  stat_sum() + 
  scale_size(range = c(1, 10))</code></pre>
<p><img src="images/stat_sum1.png" width="50%" /><img src="images/stat_sum2.png" width="50%" /></p>
<pre class="r"><code>library(ggplot2)
library(Hmisc)
wt.cyl.am &lt;- ggplot(mtcars, aes(x = cyl,  y = wt, col = am, fill = am, group = am))
posn.d &lt;- position_dodge(width = 0.1)
posn.jd &lt;- position_jitterdodge(jitter.width = 0.1, dodge.width = 0.2)
posn.j &lt;- position_jitter(width = 0.2)
# Plot 1: Jittered, dodged scatter plot with transparent points
wt.cyl.am +
  geom_point(position = posn.jd, alpha = 0.6)

# Plot 2: Mean and SD - the easy way
wt.cyl.am +
  geom_point(position = posn.jd, alpha = 0.6) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), position = posn.d)

# Plot 3: Mean and 95% CI - the easy way
wt.cyl.am +
  geom_point(position = posn.jd, alpha = 0.6) +
  stat_summary(fun.data = mean_cl_normal, position = posn.d)

# Plot 4: Mean and SD - with T-tipped error bars - fill in ___
wt.cyl.am +
  stat_summary(geom = &quot;point&quot;, fun.y = mean,
               position = posn.d) +
  stat_summary(geom = &quot;errorbar&quot;, fun.data = mean_sdl,
               position = posn.d, fun.args = list(mult = 1), width = 0.1)</code></pre>
<p><img src="images/summary1.png" width="50%" /><img src="images/summary2.png" width="50%" /><img src="images/summary3.png" width="50%" /><img src="images/summary4.png" width="50%" /></p>
<pre class="r"><code># Add three stat_summary calls to wt.cyl.am
wt.cyl.am +
  stat_summary(geom = &quot;linerange&quot;, fun.data = med_IQR,
               position = posn.d, size = 3) +
  stat_summary(geom = &quot;linerange&quot;, fun.data = gg_range,
               position = posn.d, size = 3,
               alpha = 0.4) +
  stat_summary(geom = &quot;point&quot;, fun.y = median,
               position = posn.d, size = 3,
               col = &quot;black&quot;, shape = &quot;X&quot;)</code></pre>
<p><img src="images/another.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>p &lt;- ggplot(mtcars, aes(x = wt, y = hp, col = am)) + geom_point() + geom_smooth()
# limits to set the aesthetic limit, expand is to ensure the data is placed some distance away from axes
p + scale_x_continuous(limits = c(3, 6), expand = c(0, 0))
# Add coord_cartesian(): the proper way to zoom in
p + coord_cartesian(xlim = c(3, 6))</code></pre>
<p><img src="images/point1.png" width="50%" /><img src="images/point2.png" width="50%" /></p>
<pre class="r"><code># Complete basic scatter plot function
base.plot &lt;- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, col = Species)) +
               geom_jitter() +
               geom_smooth(method = &quot;lm&quot;, se = FALSE)
base.plot
# Fix aspect ratio (1:1) of base.plot
base.plot + coord_equal(ratio = 1)
base.plot + coord_equal(ratio = 2)
base.plot + coord_equal(ratio = 3)</code></pre>
<p><img src="images/scale3.png" width="50%" /><img src="images/scale4.png" width="50%" /><img src="images/scale5.png" width="50%" /><img src="images/scale6.png" width="50%" /></p>
<pre class="r"><code>wide.bar &lt;- ggplot(mtcars, aes(x = 1, fill = cyl)) +
              geom_bar()
# Convert wide.bar to pie chart
wide.bar +
  coord_polar(theta = &quot;y&quot;)
# Create stacked bar plot: thin.bar
thin.bar &lt;- ggplot(mtcars, aes(x = 1, fill = cyl)) +
              geom_bar(width = 0.1) +
              scale_x_continuous(limits = c(0.5, 1.5))
# Convert thin.bar to &quot;ring&quot; type pie chart
thin.bar + 
  coord_polar(theta = &quot;y&quot;)</code></pre>
<p><img src="images/ring1.png" width="50%" /><img src="images/ring2.png" width="50%" /></p>
<pre class="r"><code># Basic scatter plot
p &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point()
p +
  facet_grid(am ~ .)
# 2 - Separate columns according to column cylinders, cyl
p +
  facet_grid(. ~ cyl)
# 3 - Separate by both columns and rows 
p +
  facet_grid(am ~ cyl)</code></pre>
<p><img src="images/facet_grid1.png" width="50%" /><img src="images/facet_grid2.png" width="50%" /><img src="images/facet_grid3.png" width="50%" /></p>
<p><strong>For many variables</strong></p>
<pre class="r"><code># Code to create the cyl_am col and myCol vector
mtcars$cyl_am &lt;- paste(mtcars$cyl, mtcars$am, sep = &quot;_&quot;)
myCol &lt;- rbind(brewer.pal(9, &quot;Blues&quot;)[c(3,6,8)],
               brewer.pal(9, &quot;Reds&quot;)[c(3,6,8)])
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl_am, size = disp)) +
  geom_point() +
  scale_color_manual(values = myCol) +
  facet_grid(gear ~ vs)</code></pre>
<p><img src="images/another1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Facet rows accoding to vore which is pretty hard to read, right?
p +
  facet_grid(vore ~ .)
# Specify scale and space arguments to free up rows
p +
  facet_grid(vore ~ ., scale = &quot;free_y&quot;, space = &quot;free_y&quot;)</code></pre>
<p><img src="images/free_y1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><img src="images/free_y2.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="themes-layer" class="section level1">
<h1>Themes layer</h1>
<p>Let’s look at an example first. How to transfer from left to right image?</p>
<p><img src="images/theme1.png" width="50%" /><img src="images/theme2.png" width="50%" /></p>
<div id="rectangle" class="section level2">
<h2>Rectangle</h2>
<p>We can add <code>theme</code> element to original plot:</p>
<pre class="r"><code>myPink &lt;- &quot;#FEE0D2&quot;
# Theme to remove all rectangles
no_panels &lt;- theme(rect = element_blank())
# Remove plot panels and legend and add a border, z is orginal figure
z +
  no_panels +
  theme(plot.background = element_rect(fill = myPink, color = &quot;black&quot;, size = 3))</code></pre>
</div>
<div id="line" class="section level2">
<h2>Line</h2>
<p>Next, you will think about removing grid lines in the previous figure. For each of the arguments that specify lines, use <code>element_line()</code> to create red axes and tick marks.</p>
<pre class="r"><code># z is previous figure code
z + 
  theme(panel.grid = element_blank(),
        axis.line = element_line(color = &quot;red&quot;),
        axis.ticks = element_line(color = &quot;red&quot;))</code></pre>
<p><img src="images/another2.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="text" class="section level2">
<h2>Text</h2>
<p>Now, we can make the text on your plot prettier and easier to spot. You can do this through the <code>element_text()</code> function and appropriate arguments inside the <code>theme()</code> function. The plot you’ve created previously is available as <code>z</code>.</p>
<pre class="r"><code>z +
  theme(strip.text = element_text(size = 16, color = myRed),
        axis.title = element_text(color = myRed, hjust = 0, face = &quot;italic&quot;),
        axis.text = element_text(color = &quot;black&quot;))</code></pre>
</div>
<div id="legend" class="section level2">
<h2>Legend</h2>
<p>The themes layer also allows you to specify the appearance and location of legends. Previous code is available as z.</p>
<pre class="r"><code># Move legend by position
z +
  theme(legend.position = c(0.85, 0.85))
# Change direction
z +
  theme(legend.direction = &quot;horizontal&quot;)
# Change location by name
z +
  theme(legend.position = &quot;bottom&quot;)
# Remove legend entirely
z +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="images/legend1.png" width="50%" /><img src="images/legend2.png" width="50%" /><img src="images/legend3.png" width="50%" /><img src="images/legend4.png" width="50%" /></p>
</div>
<div id="positions" class="section level2">
<h2>Positions</h2>
<p>The different rectangles of your plot have spacing between them. There’s spacing between the facets, between the axis labels and the plot rectangle, between the plot rectangle and the entire panel background, etc. The last plot you created in the previous exercise, without a legend, is available as <code>z</code>.</p>
<pre class="r"><code># Increase spacing between facets
library(grid)
z + theme(panel.spacing.x = unit(2, &quot;cm&quot;))
# Adjust the plot margin
z + theme(panel.spacing.x = unit(2, &quot;cm&quot;), plot.margin = unit(c(1,2,1,1), &quot;cm&quot;))</code></pre>
<p><img src="images/panel_spacing1.png" width="50%" /><img src="images/panel_spacing2.png" width="50%" /></p>
</div>
<div id="recycling-themes" class="section level2">
<h2>Recycling Themes</h2>
<p>If you are making many plots and wanna keep consistency in style, you might wanna apply specific theme everywhere because building your themes every time from scratch can become a pain and unnecessarily bloat your scripts. theme_update() updates the default theme used by ggplot2. The arguments for theme_update() are the same as for theme(). When you call theme_update() and assign it to an object (e.g. called old), that object stores the current default theme, and the arguments update the default theme. If you want to restore the previous default theme, you can get it back by using theme_update() again. In the following exercises, we’ll practice different ways of managing, updating and saving themes.</p>
<pre class="r"><code># Update the theme as default theme
old &lt;- theme_update(panel.background = element_blank(),
             legend.key = element_blank(),
             legend.background = element_blank(),
             strip.background = element_blank(),
             plot.background = element_rect(fill = myPink, color = &quot;black&quot;, size = 3),
             panel.grid = element_blank(),
             axis.line = element_line(color = &quot;red&quot;),
             axis.ticks = element_line(color = &quot;red&quot;),
             strip.text = element_text(size = 16, color = myRed),
             axis.title.y = element_text(color = myRed, hjust = 0, face = &quot;italic&quot;),
             axis.title.x = element_text(color = myRed, hjust = 0, face = &quot;italic&quot;),
             axis.text = element_text(color = &quot;black&quot;),
             legend.position = &quot;none&quot;)

# 3 - Display the plot z2 - new default theme used
z2
# 4 - Restore the old default theme
theme_set(old)</code></pre>
<p><img src="images/legend4.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="exploring-ggthemes" class="section level2">
<h2>Exploring ggthemes</h2>
<p>Here is a nice website you can refer to, <a href="https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/">All your figure are belong to us</a>. The author almost made a list of all whay you need in his/her website.</p>
<pre class="r"><code>library(ggthemes)
z2
# Apply theme_tufte(), plot additional modifications
custom_theme &lt;- theme_tufte() +
  theme(legend.position = c(0.9, 0.9),
        legend.title = element_text(face = &quot;italic&quot;, size = 12),
        axis.title = element_text(face = &quot;bold&quot;, size = 14))

# Draw the customized plot
z2 + custom_theme
# Use theme_set to set custom theme as default
theme_set(custom_theme)</code></pre>
<p><img src="images/element_text1.png" width="50%" /><img src="images/element_text2.png" width="50%" /></p>
</div>
</div>
<div id="bar-plots" class="section level1">
<h1>Bar Plots</h1>
<p>“dynamite plots” (bar plots with error bars) are not well suited for their intended purpose of depicting distributions. If you really want error bars on bar plots, you can still get that. However, you’ll need to set the positions manually. A point geom will typically serve you much better. For base layer:</p>
<pre class="r"><code>m &lt;- ggplot(mtcars, aes(x = cyl, y = wt))
# Draw dynamite plot
m +
  stat_summary(fun.y = mean, geom = &quot;bar&quot;, fill = &quot;skyblue&quot;) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = &quot;errorbar&quot;, width = 0.1)</code></pre>
<p><img src="images/another3.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The plot is not that good, right? Let’s handle it.</p>
<pre class="r"><code>m &lt;- ggplot(mtcars, aes(x = cyl,y = wt, col = am, fill = am))
# Plot 2: Set position dodge in each stat function which does not solve problem
m +
  stat_summary(fun.y = mean, geom = &quot;bar&quot;, position = &quot;dodge&quot;) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), 
               geom = &quot;errorbar&quot;, width = 0.1, position = &quot;dodge&quot;)
# Set your dodge posn manually
posn.d &lt;- position_dodge(0.9)
# Plot 3: Redraw dynamite plot
m +
  stat_summary(fun.y = mean, geom = &quot;bar&quot;, position = posn.d) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = &quot;errorbar&quot;, width = 0.1, position = posn.d)</code></pre>
<p><img src="images/red1.png" width="50%" /><img src="images/red2.png" width="50%" /></p>
<p>If it is appropriate to use bar plots (see the video for a discussion!), then it would also be nice to give an impression of the number of values in each group. stat_summary() doesn’t keep track of the count. stat_sum() does (that’s the whole point), but it’s difficult to access. In this case, the most straightforward thing to do is calculate exactly what we want to plot beforehand. For this exercise we’ve created a summary data frame called mtcars.cyl which contains the average (wt.avg), standard deviations (sd) and count (n) of car weights, according to cylinders, cyl. It also contains the proportion (prop) of each cylinder represented in the entire dataset. Use the console to familiarize yourself with the mtcars.cyl data frame.</p>
<pre class="r"><code># Base layers
m &lt;- ggplot(mtcars.cyl, aes(x = cyl, y = wt.avg))
# Plot 1: Draw bar plot with geom_bar
m + geom_bar(stat = &quot;identity&quot;, fill = &quot;skyblue&quot;)
# Plot 2: Draw bar plot with geom_col
m + geom_col(fill = &quot;skyblue&quot;)
# Plot 3: geom_col with variable widths.
m + geom_col(fill = &quot;skyblue&quot;, width = mtcars.cyl$prop)
# Plot 4: Add error bars
m +
  geom_col(fill = &quot;skyblue&quot;, width = mtcars.cyl$prop) +
  geom_errorbar(aes(ymin = wt.avg - sd, ymax = wt.avg + sd), width = 0.1)</code></pre>
<p><img src="images/geom_col1.png" width="50%" /><img src="images/geom_col2.png" width="50%" /><img src="images/geom_col3.png" width="50%" /><img src="images/geom_col4.png" width="50%" /></p>
</div>
<div id="pie-charts" class="section level1">
<h1>Pie Charts</h1>
<p>Convert bar chart to pie chart:</p>
<pre class="r"><code># Plot 1
ggplot(mtcars, aes(x = factor(1), fill = am)) +
  geom_bar(position = &quot;fill&quot;) +
  facet_grid(. ~ cyl) + # Facets
  coord_polar(theta = &quot;y&quot;) + # Coordinates
  theme_void()
# Plot 2
ggplot(mtcars, aes(x = factor(1), fill = am)) +
  geom_bar(position = &quot;fill&quot;, width = 1) +
  facet_grid(. ~ cyl) + # Facets
  coord_polar(theta = &quot;x&quot;) + # Coordinates
  theme_void()
# Plot 3
ggplot(mtcars, aes(x = factor(1), fill = am)) +
  geom_bar(position = &quot;fill&quot;, width = 1) +
  facet_grid(. ~ cyl) + # Facets
  coord_polar(theta = &quot;y&quot;) + # Coordinates
# Plot 4
ggplot(mtcars, aes(x = factor(1), fill = am)) +
  geom_bar(position = &quot;fill&quot;, width = 1) +
  facet_grid(. ~ cyl) + # Facets
  coord_polar(theta = &quot;y&quot;) + # Coordinates
  theme_void()</code></pre>
<p><img src="images/pie1.png" width="50%" /><img src="images/pie2.png" width="50%" /><img src="images/pie3.png" width="50%" /><img src="images/pie4.png" width="50%" /></p>
<p>The trick is to use a parallel coordinates plot. Each variable is plotted on its own parallel axis. Individual observations are connected with lines, colored according to a variable of interest. This is a surprisingly useful visualization since we can combine many variables, even if they are on entirely different scales.</p>
<p><strong>A word of caution though</strong>: typically it is very taboo to draw lines in this way. It’s the reason why we don’t draw lines across levels of a nominal variable - the order, and thus the slope of the line, is meaningless. Parallel plots are a (very useful) exception to the rule! But to be honest, i do not know much about this plot. To me, it is too complicated and meaningless when you first see it. It says it is an excellent example of an exploratory plot. In case i will explore it in the future, i will record it here.</p>
<pre class="r"><code># Parallel coordinates plot using GGally
library(GGally)
# All columns except am
group_by_am &lt;- 9
my_names_am &lt;- (1:11)[-group_by_am]
# Basic parallel plot - each variable plotted as a z-score transformation
ggparcoord(mtcars, my_names_am, groupColumn = group_by_am, alpha = 0.8)</code></pre>
<p><img src="images/another4.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="plot-matrix" class="section level1">
<h1>Plot Matrix</h1>
<p>Another great example is a plot matrix. <code>GGally::ggpairs(mtcars2)</code> will produce the plot of a selection of the <code>mtcars</code> dataset, <code>mtcars2</code>.</p>
<p><img src="images/matrix1.png" width="50%" /><img src="images/matrix2.png" width="50%" /></p>
</div>
<div id="heat-maps" class="section level1">
<h1>Heat Maps</h1>
<p>Just for exploratory thinking of your data, not good for publication though.</p>
<pre class="r"><code># Create color palette
myColors &lt;- brewer.pal(9, &quot;Reds&quot;)
# Build the heat map using geom_tile
ggplot(barley, aes(x = year, y = variety, fill = yield)) +
  geom_tile() + # Geom layer
  facet_wrap( ~ site, ncol = 1) + # ensure there is just one column
  scale_fill_gradientn(colors = myColors) # Adjust colors</code></pre>
<p><img src="images/another5.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="heat-maps-alternatives" class="section level2">
<h2>Heat maps alternatives</h2>
<p>There are several alternatives to heat maps. The best choice really depends on the data and the story you want to tell with this data.</p>
<pre class="r"><code># Line plot; check group argument meaning
ggplot(barley, aes(x = year, y = yield, col = variety, group = variety))  + 
  geom_line() + 
  facet_wrap( ~ site, nrow = 1)</code></pre>
<p><img src="images/another6.png" width="70%" style="display: block; margin: auto;" /></p>
<p>You can use dodged error bars or you can use overlapping transparent ribbons. We’ll try to recreate the second option, the transparent ribbons here.</p>
<pre class="r"><code># Create overlapping ribbon plot from scratch
ggplot(barley, aes(x = year, y = yield, col = site, fill = site, group = site)) +
  stat_summary(fun.y = mean, geom = &quot;line&quot;) +
  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = &quot;ribbon&quot;, col = NA, alpha = 0.1)</code></pre>
<p><img src="images/another7.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="case-study" class="section level1">
<h1>Case Study</h1>
<pre class="r"><code># Age colored by BMI, binwidth = 1
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(binwidth = 1)</code></pre>
<p><img src="images/another8.png" width="70%" style="display: block; margin: auto;" /></p>
<p>When we introduced histograms we focused on univariate data, which is exactly what we’ve been doing here. However, when we want to explore distributions further there is much more we can do. For example, there are density and frequency plots.</p>
<pre class="r"><code># The color scale used in the plot
BMI_fill &lt;- scale_fill_brewer(&quot;BMI Category&quot;, palette = &quot;Reds&quot;)
# Theme to fix category display in faceted plot
fix_strips &lt;- theme(strip.text.y = element_text(angle = 0, hjust = 0, vjust = 0.1, size = 14),
                    strip.background = element_blank(),
                    legend.position = &quot;none&quot;)
# Histogram, add BMI_fill and customizations
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(binwidth = 1) +
  fix_strips +
  BMI_fill +
  facet_grid(RBMI ~ .) +
  theme_classic()</code></pre>
<p><img src="images/another9.png" width="70%" style="display: block; margin: auto;" /></p>
<p>In the previous exercise we looked at different ways of showing the absolute count of multiple histograms. This is fine, but density would be a more useful measure if we wanted to see how the frequency of one variable changes across another.</p>
<pre class="r"><code># Plot 1 - Count histogram
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) +
  geom_histogram(binwidth = 1) +
  BMI_fill
# Plot 2 - Density histogram
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(aes(y = ..density..), binwidth = 1) +
  BMI_fill
# Plot 3 - Faceted count histogram
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) +
  geom_histogram(binwidth = 1) +
  BMI_fill + 
  facet_grid(RBMI ~ .)
# Plot 4 - Faceted density histogram
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(aes(y = ..density..), binwidth = 1) +
  BMI_fill +
  facet_grid(RBMI ~ .)
# Plot 5 - Density histogram with position = &quot;fill&quot;
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(aes(y = ..density..), binwidth = 1, position = &quot;fill&quot;) +
  BMI_fill
# Plot 6 - The accurate histogram
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) + 
  geom_histogram(aes(y = ..count../sum(..count..)), binwidth = 1, position = &quot;fill&quot;) +
  BMI_fill</code></pre>
<p><img src="images/density1.png" width="50%" /><img src="images/density2.png" width="50%" /><img src="images/density3.png" width="50%" /><img src="images/density4.png" width="50%" /><img src="images/density5.png" width="50%" /><img src="images/density6.png" width="50%" /></p>
<pre class="r"><code># An attempt to facet the accurate frequency histogram from before (failed)
ggplot(adult, aes (x = SRAGE_P, fill= factor(RBMI))) +
  geom_histogram(aes(y = ..count../sum(..count..)), binwidth = 1, position = &quot;fill&quot;) +
  BMI_fill +
  facet_grid(RBMI ~ .)

# Create DF with table()
DF &lt;- table(adult$RBMI, adult$SRAGE_P)
# Use apply on DF to get frequency of each group
DF_freq &lt;- apply(DF, 2, function(x) x/sum(x)) # 2 means 2 columns
# Load reshape2 and use melt on DF to create DF_melted
library(reshape2)
DF_melted &lt;- melt(DF_freq)
# Change names of DF_melted
names(DF_melted) &lt;- c(&quot;FILL&quot;, &quot;X&quot;, &quot;value&quot;)
# Add code to make this a faceted plot
ggplot(DF_melted, aes(x = X, y = value, fill = FILL)) +
  geom_col(position = &quot;stack&quot;) + # we can use geom_col instead of geom_bar(stat = &quot;identity&quot;)
  BMI_fill + 
  facet_grid(FILL ~ .) # Facets</code></pre>
<p><img src="images/stack1.png" width="50%" /><img src="images/stack2.png" width="50%" /></p>
<div id="mosaic-plots-useful" class="section level2">
<h2>Mosaic Plots (Useful)</h2>
<p>You may have already realized that bars are simply rectangles, but we don’t have easy access to the xmin and xmax aesthetics, but in geom_rect() we do! Likewise, we also have access to ymin and ymax.</p>
<pre class="r"><code># The initial contingency table
DF &lt;- as.data.frame.matrix(table(adult$SRAGE_P, adult$RBMI))
# Create groupSum, xmax and xmin columns
DF$groupSum &lt;- rowSums(DF)
DF$xmax &lt;- cumsum(DF$groupSum)
DF$xmin &lt;- DF$xmax - DF$groupSum
# The groupSum column needs to be removed; don&#39;t remove this line
DF$groupSum &lt;- NULL
# Copy row names to variable X
DF$X &lt;- row.names(DF)
# Melt the dataset
library(reshape2)
DF_melted &lt;- melt(DF, id.vars = c(&quot;X&quot;, &quot;xmin&quot;, &quot;xmax&quot;), variable.name = &quot;FILL&quot;)
# dplyr call to calculate ymin and ymax - don&#39;t change
library(dplyr)
DF_melted &lt;- DF_melted %&gt;%
  group_by(X) %&gt;%
  mutate(ymax = cumsum(value/sum(value)),
         ymin = ymax - value/sum(value))
# Plot rectangles - don&#39;t change
library(ggthemes)
ggplot(DF_melted, aes(ymin = ymin,
                 ymax = ymax,
                 xmin = xmin,
                 xmax = xmax,
                 fill = FILL)) +
  geom_rect(colour = &quot;white&quot;) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  BMI_fill +
  theme_tufte()</code></pre>
<p><img src="images/another10.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Perform chi.sq test (RBMI and SRAGE_P)
results &lt;- chisq.test(table(adult$RBMI, adult$SRAGE_P))
# Melt results$residuals and store as resid
resid &lt;- melt(results$residuals)
# Change names of resid
names(resid) &lt;- c(&quot;FILL&quot;, &quot;X&quot;, &quot;residual&quot;)
# merge the two datasets:
DF_all &lt;- merge(DF_melted, resid)
# Update plot command
library(ggthemes)
ggplot(DF_all, aes(ymin = ymin,
                   ymax = ymax,
                   xmin = xmin,
                   xmax = xmax,
                   fill = residual)) +
  geom_rect() +
  scale_fill_gradient2() +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  theme_tufte()</code></pre>
<p><img src="images/another11.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Since we’re not coloring according to BMI, we have to add group (and x axis) labels manually. The first two commands show how we got the the four positions for the y axis labels. First, we got the position of the maximum xmax values, i.e. at the very right end, stored as index. We want to calculate the half difference between each pair of ymax and ymin (e.g. (ymax - ymin)/2) at these index positions, then add this value to the ymin value. These positions are stored in the variable yposn.</p>
<pre class="r"><code># Position for labels on y axis (don&#39;t change)
index &lt;- DF_all$xmax == max(DF_all$xmax)
DF_all$yposn &lt;- DF_all$ymin[index] + (DF_all$ymax[index] - DF_all$ymin[index])/2
# Plot 1: geom_text for BMI (i.e. the fill axis)
p1 &lt;- p %+% DF_all + 
  geom_text(aes(x = max(xmax), 
               y = yposn,
               label = FILL),
            size = 3, hjust = 1,
            show.legend  = FALSE)
p1

# Plot 2: Position for labels on x axis
DF_all$xposn &lt;- DF_all$xmin + (DF_all$xmax - DF_all$xmin)/2
# geom_text for ages (i.e. the x axis)
p1 %+% DF_all + 
  geom_text(aes(x = xposn, label = x),
            y = 1, angle = 90,
            size = 3, hjust = 1,
            show.legend = FALSE)</code></pre>
<p><img src="images/residual1.png" width="50%" /><img src="images/residual2.png" width="50%" /></p>
<p>Notice that the function, <code>mosaicGG()</code>, takes multiple arguments, such as the data frame of interest and the variables that you want to create the mosaic plot for. None of the arguments have default values, so you’ll have to specify all three if you want the mosaicGG() function to work.</p>
<pre class="r"><code># Load all packages
library(ggplot2)
library(reshape2)
library(dplyr)
library(ggthemes)
# BMI described by age (as previously seen)
mosaicGG(adult, X = &quot;SRAGE_P&quot;, FILL = &quot;RBMI&quot;)
# Poverty described by age
mosaicGG(adult, X = &quot;SRAGE_P&quot;, FILL = &quot;POVLL&quot;)
# mtcars: am described by cyl
mosaicGG(mtcars, &quot;cyl&quot;, &quot;am&quot;)
# Vocab: vocabulary described by education
library(carData)
mosaicGG(Vocab, &quot;education&quot;, &quot;vocabulary&quot;)</code></pre>
<p><img src="images/mosaic1.png" width="50%" /><img src="images/mosaic2.png" width="50%" /><img src="images/mosaic3.png" width="50%" /><img src="images/mosaic4.png" width="50%" /></p>
<pre class="r"><code># Create movies_small
library(ggplot2movies)# movies data is in this package
library(ggplot2)
library(Hmisc)
set.seed(123)
movies_small &lt;- movies[sample(nrow(movies), 1000), ] # a random sample of 1000 observations from the larger movies dataset
movies_small$rating &lt;- factor(round(movies_small$rating))
# Build a scatter plot with mean and 95% CI
ggplot(movies_small, aes(x = rating, y = votes)) +
  geom_point() +
  stat_summary(fun.data = &quot;mean_cl_normal&quot;,  # depicts the mean and the 95% CI
               geom = &quot;crossbar&quot;,
               width = 0.2,
               col = &quot;red&quot;) +
  scale_y_log10() # transform the y scale</code></pre>
<p><img src="rstudio_files/figure-html/unnamed-chunk-159-1.png" width="864" /></p>
<pre class="r"><code>ggplot(diamonds, aes(x = carat, y = price, col = color)) +
  geom_point(alpha = 0.5, size = 0.5, shape = 16) +
  scale_x_log10(expression(log[10](Carat)), limits = c(0.1,10)) +
  scale_y_log10(expression(log[10](Price)), limits = c(100,100000)) + # Transform both axes to log10 scales using the aforementioned scale functions
  scale_color_brewer(palette = &quot;YlOrRd&quot;) +
  coord_equal() +
  theme_classic()</code></pre>
<p><img src="images/another12.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Converse point plot to smooth plot:</p>
<pre class="r"><code># Add smooth layer and facet the plot
ggplot(diamonds, aes(x = carat, y = price, col = color)) +
  stat_smooth(method = &quot;lm&quot;) +
  scale_x_log10(expression(log[10](Carat)), limits = c(0.1,10)) +
  scale_y_log10(expression(log[10](Price)), limits = c(100,100000)) +
  scale_color_brewer(palette = &quot;YlOrRd&quot;) +
  coord_equal() +
  theme_classic()</code></pre>
<p><img src="images/another13.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>d &lt;- ggplot(movies_small, aes(x = rating, y = votes)) +
  geom_point() +
  geom_boxplot() +
  stat_summary(fun.data = &quot;mean_cl_normal&quot;,
               geom = &quot;crossbar&quot;,
               width = 0.2,
               col = &quot;red&quot;)
# Untransformed plot
d
# the transformation happens before calculating the statistics
d + scale_y_log10() 
# the transformation happens after calculating the statistics
d + coord_trans(y = &quot;log10&quot;)</code></pre>
<p><img src="images/cl_image1.png" width="50%" /><img src="images/cl_image2.png" width="50%" /></p>
<p>If you only have continuous variables, you can convert them into ordinal variables using any of the following functions:</p>
<ul>
<li><code>cut_interval(x, n)</code> makes <code>n</code> groups from vector <code>x</code> with equal range.</li>
<li><code>cut_number(x, n)</code> makes <code>n</code> groups from vector <code>x</code> with (approximately) equal numbers of observations.</li>
<li><code>cut_width(x, width)</code> makes groups of width width from vector <code>x</code>.</li>
</ul>
<p>This is useful when you want to summarize a complex scatter plot like the one shown in the plot1.</p>
<p><img src="images/geom_boxplot1.png" width="50%" /><img src="images/geom_boxplot2.png" width="50%" /><img src="images/geom_boxplot3.png" width="50%" /><img src="images/geom_boxplot4.png" width="50%" /></p>
</div>
</div>
<div id="density-plots" class="section level1">
<h1>Density Plots</h1>
<p>The following default parameters are used (you can specify these arguments both in <code>density()</code> as well as <code>geom_density()</code>):</p>
<ul>
<li><code>bw = &quot;nrd0&quot;</code>, telling R which rule to use to choose an appropriate bandwidth.</li>
<li><code>kernel = &quot;gaussian&quot;</code>, telling R to use the Gaussian kernel.</li>
</ul>
<p>You could have a good understanding through <a href="http://sape.inf.usi.ch/quick-reference/ggplot2/geom_rug">ggplot2 Quick Reference: geom_rug</a>.</p>
<pre class="r"><code># Calculating density: d
d &lt;- density(test_data$norm)
# Use which.max() to calculate mode and specify x
mode &lt;- d$x[which.max(d$y)]
# Finish the ggplot call
ggplot(test_data, aes(x = norm)) +
  geom_rug() +
  geom_density() +
  geom_vline(xintercept = mode, col = &quot;red&quot;)</code></pre>
<p><img src="images/another14.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Now that you know how to create a empirical and theoretical density plot, we should compare them in a plot then.</p>
<pre class="r"><code>fun_args &lt;- list(mean = mean(test_data$norm), sd = sd(test_data$norm))
ggplot(test_data, aes(x = norm)) +
  geom_histogram(aes(y = ..density..)) +
  geom_density(col = &quot;red&quot;) + # empirical
  stat_function(fun = dnorm, args = fun_args, col = &quot;blue&quot;) # theoretical</code></pre>
<p><img src="images/another15.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="adjusting-density-plots" class="section level2">
<h2>Adjusting density plots</h2>
<p>There are three parameters that you may be tempted to adjust in a density plot:</p>
<ul>
<li>bw - the smoothing bandwidth to be used, see ?density for details</li>
<li>adjust - adjustment of the bandwidth, see density for details</li>
<li>kernel - kernel used for density estimation, defined as
<ul>
<li>“g” = gaussian</li>
<li>“r” = rectangular</li>
<li>“t” = triangular</li>
<li>“e” = epanechnikov</li>
<li>“b” = biweight</li>
<li>“c” = cosine</li>
<li>“o” = optcosine</li>
</ul></li>
</ul>
<p>you’ll use a dataset containing only four points, <code>small_data</code>, so that you can see how these three arguments affect the shape of the density plot.</p>
<pre class="r"><code># Get the default bandwith
get_bw &lt;- density(small_data$x)$bw
# Basic plotting object
p &lt;- ggplot(small_data, aes(x = x)) +
  geom_rug() +
  coord_cartesian(ylim = c(0,0.5))
# Create three plots
p + geom_density()
p + geom_density(adjust = 0.25)
p + geom_density(bw = 0.25 * get_bw)
# Create two plots
p + geom_density(kernel = &quot;r&quot;)
p + geom_density(kernel = &quot;e&quot;)</code></pre>
<p><img src="images/empirical1.png" width="50%" /><img src="images/empirical2.png" width="50%" /><img src="images/empirical3.png" width="50%" /><img src="images/empirical4.png" width="50%" /><img src="images/empirical5.png" width="50%" /></p>
<p>A drawback of showing a box plot per group, is that you don’t have any indication of the sample size, <code>n</code>, in each group, that went into making the plot. One way of dealing with this is to use a variable width for the box, which reflects differences in <code>n</code>. Here is an example:</p>
<pre class="r"><code>ggplot(diamonds, aes(x = cut, y = price, col = color)) +
  geom_boxplot(varwidth = T) +
  facet_grid(. ~ color)</code></pre>
<p><img src="rstudio_files/figure-html/unnamed-chunk-173-1.png" width="864" /></p>
<pre class="r"><code># Individual densities
ggplot(mammals[mammals$vore == &quot;Insectivore&quot;, ], aes(x = sleep_total, fill = vore)) +
  geom_density(col = NA, alpha = 0.35) +
  scale_x_continuous(limits = c(0, 24)) +
  coord_cartesian(ylim = c(0, 0.3))

# With faceting
ggplot(mammals, aes(x = sleep_total, fill = vore)) +
  geom_density(col = NA, alpha = 0.35) +
  scale_x_continuous(limits = c(0, 24)) +
  coord_cartesian(ylim = c(0, 0.3)) +
  facet_wrap( ~ vore, nrow = 2)

# Note that by default, the x ranges fill the scale
ggplot(mammals, aes(x = sleep_total, fill = vore)) +
  geom_density(col = NA, alpha = 0.35) +
  scale_x_continuous(limits = c(0, 24)) +
  coord_cartesian(ylim = c(0, 0.3))

# Trim each density plot individually
ggplot(mammals, aes(x = sleep_total, fill = vore)) +
  geom_density(col = NA, alpha = 0.35, trim = TRUE) +
  scale_x_continuous(limits=c(0,24)) +
  coord_cartesian(ylim = c(0, 0.3))</code></pre>
<p><img src="images/mammals1.png" width="50%" /><img src="images/mammals2.png" width="50%" /><img src="images/mammals3.png" width="50%" /><img src="images/mammals4.png" width="50%" /></p>
<pre class="r"><code># Unweighted density plot from before
ggplot(mammals, aes(x = sleep_total, fill = vore)) +
  geom_density(col = NA, alpha = 0.35) +
  scale_x_continuous(limits = c(0, 24)) +
  coord_cartesian(ylim = c(0, 0.3))

# Unweighted violin plot
ggplot(mammals, aes(x = vore, y = sleep_total, fill = vore)) +
  geom_violin()

# Calculate weighting measure
library(dplyr)
mammals2 &lt;- mammals %&gt;%
  group_by(vore) %&gt;%
  mutate(n = n() / nrow(mammals)) -&gt; mammals

# Weighted density plot
ggplot(mammals2, aes(x = sleep_total, fill = vore)) +
  geom_density(aes(weight = n), col = NA, alpha = 0.35) +
  scale_x_continuous(limits = c(0, 24)) +
  coord_cartesian(ylim = c(0, 0.3))

# Weighted violin plot
ggplot(mammals2, aes(x = vore, y = sleep_total, fill = vore)) +
  geom_violin(aes(weight = n), col = NA)</code></pre>
<p><img src="images/violin1.png" width="50%" /><img src="images/violin2.png" width="50%" /><img src="images/violin3.png" width="50%" /><img src="images/violin4.png" width="50%" /></p>
</div>
<div id="d-density-plots" class="section level2">
<h2>2D Density Plots</h2>
<p>You can consider two orthogonal density plots in the form of a 2D density plot. Just like with a 1D density plot, you can adjust the bandwidth of both axes independently.</p>
<pre class="r"><code># Base layers
library(datasets)
p &lt;- ggplot(faithful, aes(x = waiting, y = eruptions)) +
  scale_y_continuous(limits = c(1, 5.5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(40, 100), expand = c(0, 0)) +
  coord_fixed(60 / 4.5)

# 1 - Use geom_density_2d()
p + geom_density_2d()</code></pre>
<p><img src="rstudio_files/figure-html/unnamed-chunk-178-1.png" width="864" /></p>
<pre class="r"><code># 2 - Use stat_density_2d() with arguments
p + stat_density_2d(aes(col = ..level..), h = c(5, 0.5))</code></pre>
<p><img src="rstudio_files/figure-html/unnamed-chunk-178-2.png" width="864" /></p>
<p>Here you’ll explore the viridis package. This package contains multi-hue color palettes suitable for continuous variables. The advantage of these scales is that instead of providing an even color gradient for a continuous scale, they highlight the highest values by using an uneven color gradient on purpose. The high values are lighter colors (yellow versus blue), so they stand out more.</p>
<pre class="r"><code>library(viridis)</code></pre>
<pre><code>## Loading required package: viridisLite</code></pre>
<pre class="r"><code># Add viridis color scale
ggplot(faithful, aes(x = waiting, y = eruptions)) +
  scale_y_continuous(limits = c(1, 5.5), expand = c(0,0)) +
  scale_x_continuous(limits = c(40, 100), expand = c(0,0)) +
  coord_fixed(60/4.5) +
  stat_density_2d(geom = &quot;tile&quot;, aes(fill = ..density..), h=c(5,.5), contour = FALSE)+
  scale_fill_viridis()</code></pre>
<p><img src="rstudio_files/figure-html/unnamed-chunk-179-1.png" width="864" /></p>
</div>
</div>
<div id="for-large-data" class="section level1">
<h1>For Large Data</h1>
<pre class="r"><code># pairs
pairs(iris[1:4])
# chart.Correlation
library(PerformanceAnalytics)
chart.Correlation(iris[1:4])
# ggpairs
library(GGally)
ggpairs(mtcars_fact[1:3])</code></pre>
<p><img src="images/correlation1.png" width="50%" /><img src="images/correlation2.png" width="50%" /><img src="images/correlation3.png" width="50%" /></p>
<pre class="r"><code>library(ggplot2)
library(reshape2)
cor_list &lt;- function(x) {
  L &lt;- M &lt;- cor(x)
  
  M[lower.tri(M, diag = TRUE)] &lt;- NA
  M &lt;- melt(M)
  names(M)[3] &lt;- &quot;points&quot;
  
  L[upper.tri(L, diag = TRUE)] &lt;- NA
  L &lt;- melt(L)
  names(L)[3] &lt;- &quot;labels&quot;
  
  merge(M, L)
}
# Calculate xx with cor_list
library(dplyr)
xx &lt;- iris %&gt;%
  group_by(Species) %&gt;%
  do(cor_list(.[1:4])) 
# Finish the plot
ggplot(xx, aes(x = Var1, y = Var2)) +
  geom_point(aes(col = points, size = abs(points)), shape = 16) +
  geom_text(aes(col = labels,  size = abs(labels), label = round(labels, 2))) +
  scale_size(range = c(0, 6)) +
  scale_color_gradient(&quot;r&quot;, limits = c(-1, 1)) +
  scale_y_discrete(&quot;&quot;, limits = rev(levels(xx$Var1))) +
  scale_x_discrete(&quot;&quot;) +
  guides(size = FALSE) +
  geom_abline(slope = -1, intercept = nlevels(xx$Var1) + 1) +
  coord_fixed() +
  facet_grid(. ~ Species) +
  theme(axis.text.y = element_text(angle = 45, hjust = 1),
        axis.text.x = element_text(angle = 45, hjust = 1),
        strip.background = element_blank())</code></pre>
<p><img src="images/another16.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="ternary-or-triangle-plot" class="section level2">
<h2>Ternary or Triangle Plot</h2>
<pre class="r"><code># Add an ID column from the row.names
africa_sample$ID &lt;- row.names(africa_sample)
# Gather africa_sample
library(tidyr)
africa_sample_tidy &lt;- gather(africa_sample, key, value, -ID)
head(africa_sample_tidy)
# Finish the ggplot command
ggplot(africa_sample_tidy, aes(x = factor(ID), y = value, fill = key)) +
  geom_col() +
  coord_flip()</code></pre>
<p><img src="images/another17.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Load ggtern
library(ggtern)

# Build ternary plot
ggtern(africa, aes(x = Sand, y = Silt, z = Clay)) +
  geom_point(shape = 16, alpha = 0.2)</code></pre>
<p><img src="images/another18.png" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>Adjust ternary plots</strong></p>
<p>Ternary plots have been around for a while in R; you could achieve the same thing with the vcd package authored by Michael Friendly. If you just need a quick and dirty ternary plot, that may suit you just fine. However, since ggtern is built on ggplot2, you can take advantage of all the tools available therein.</p>
<pre class="r"><code># Contour plot
ggtern(africa, aes(x = Sand, y = Silt, z = Clay)) +
  geom_density_tern()
# Density olot which i prefer
ggtern(africa, aes(x = Sand, y = Silt, z = Clay)) +
  stat_density_tern(geom = &quot;polygon&quot;, aes(fill = ..level.., alpha = ..level..)) +
  guides(fill = FALSE)</code></pre>
<p><img src="images/ternary1.png" width="50%" /><img src="images/ternary2.png" width="50%" /></p>
</div>
</div>
<div id="build-the-network" class="section level1">
<h1>Build the network</h1>
</div>
<div id="merge-edges-and-vertices" class="section level1">
<h1>Merge edges and vertices</h1>
<p>mmnet &lt;- merge(madmen<span class="math inline">\(edges, madmen\)</span>vertices, by.x = “Name1”, by.y = “label”, all = TRUE) # Finish the ggplot command ggplot(data = mmnet, aes(from_id = Name1, to_id = Name2)) + geom_net(aes(col = Gender), size = 6, linewidth = 1, labelon = TRUE, fontsize = 3, labelcolour = “black”)</p>
<pre class="r"><code># Merge edges and vertices
mmnet &lt;- merge(madmen$edges, madmen$vertices,
               by.x = &quot;Name1&quot;, by.y = &quot;label&quot;,
               all = TRUE)

# Finish the ggplot command
ggplot(data = mmnet, aes(from_id = Name1, to_id = Name2)) +
  geom_net(aes(col = Gender), size = 6, linewidth = 1, labelon = TRUE, fontsize = 3, labelcolour = &quot;black&quot;)</code></pre>
<p><img src="images/another19.png" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>Adjusting the network</strong></p>
<pre class="r"><code># Node colors
pink_and_blue &lt;- c(female = &quot;#FF69B4&quot;, male = &quot;#0099ff&quot;)
# Tweak the network plot
ggplot(data = mmnet, aes(from_id = Name1, to_id = Name2)) +
  geom_net(aes(col = Gender),
           size = 6,
           linewidth = 1,
           labelon = TRUE,
           fontsize = 3,
           labelcolour = &quot;black&quot;,
           # Make the graph directed
           directed = TRUE) +
  # Add manual color scale         
  scale_color_manual(values = pink_and_blue) +
  # Set x-axis limits
  xlim(-0.05, 1.05) +
  # Set void theme
  theme_void() # remove all background elements like axes and grid lines to make a clean network plot</code></pre>
<p><img src="images/another20.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="diagnostic-plots" class="section level1">
<h1>Diagnostic Plots</h1>
<p>R has several plotting methods for specific objects. For example using <code>plot()</code> on the results of an <code>lm()</code> call results in four plots that give you insight into how well the assigned model fits the data.</p>
<p>The <code>ggfortify</code> package is an all-purpose plot converter between base graphics and ggplot2 grid graphics. For now, just know that if you want to use the automatic output features in the context of <code>ggplot2</code>, they must first be converted to a ggplot object via <code>ggfortify</code>. This can be important at the superficial level, for consistency in appearance, but also at a deeper level, for later combining several plots in a single graphics device.</p>
<pre class="r"><code># Create linear model: res
res &lt;- lm(Volume ~ Girth, data = trees)
# Plot res
plot(res) # four figures seperated
# Import ggfortify and use autoplot()
library(ggfortify)
library(ggplot2)
autoplot(res, ncol = 2)</code></pre>
<p><img src="images/fitted1.png" width="50%" /><img src="images/fitted2.png" width="50%" /><img src="images/fitted3.png" width="50%" /><img src="images/fitted4.png" width="50%" /><img src="images/fitted5.png" width="50%" /></p>
<p>**ggfortify - time series</p>
<pre class="r"><code># Call plot() on Canada
plot(Canada)
# Call autoplot() on Canada
autoplot(Canada)</code></pre>
<p><img src="images/canada1.png" width="50%" /><img src="images/canada2.png" width="50%" /></p>
<pre class="r"><code># Autoplot + ggplot2 tweaking
autoplot(eurodist) +
  coord_fixed()
# Autoplot of MDS
autoplot(cmdscale(eurodist, eig = TRUE),
         label = TRUE, 
         label.size = 3, 
         size = 0)</code></pre>
<p><img src="images/ggfortify1.png" width="50%" /><img src="images/ggfortify2.png" width="50%" /></p>
<p><strong>Plotting K-means clustering</strong></p>
<pre class="r"><code># Perform clustering
iris_k &lt;- kmeans(iris[-5], 3)
# Autplot: color according to cluster
autoplot(iris_k, data = iris, frame = TRUE)
# Autoplot: above, plus shape according to species
autoplot(iris_k, data = iris, frame = TRUE, shape = &#39;Species&#39;)</code></pre>
<p><img src="images/cluster1.png" width="50%" /><img src="images/cluster2.png" width="50%" /></p>
</div>
<div id="time-series" class="section level1">
<h1>Time Series</h1>
<div id="xts-package" class="section level2">
<h2><code>xts</code> package</h2>
<p>The main <code>xts</code> constructor takes a number of arguments, but the two most important are <code>x</code> for the data and order.by for the index. <code>x</code> must be a vector or matrix. order.by is a vector which must be the same length or number of rows as <code>x</code>, be a proper time or date object (very important!), and be in increasing order.</p>
<pre class="r"><code># Create the object data using 5 random numbers
data &lt;- rnorm(5)
# Create dates as a Date class object starting from 2016-01-01
dates &lt;- seq(as.Date(&quot;2016-01-01&quot;), length = 5, by = &quot;days&quot;)
# Use xts() to create smith
smith &lt;- xts(x = data, order.by = dates)
# Create bday (1899-05-08) using a POSIXct date class object
bday &lt;- as.POSIXct(&quot;1899-05-08&quot;)
# Create hayek and add a new attribute called born
hayek &lt;- xts(x = data, order.by = dates, born = bday)</code></pre>
<p>The most important of these attributes is the index. The index holds all the information we need for xts to treat our data as a time series. When working with time series, it will sometimes be necessary to separate your time series into its core data and index attributes for additional analysis and manipulation. The core data is the matrix portion of xts. You can separate this from the xts object using <code>coredata()</code>. The index portion of the xts object is available using the <code>index()</code> function. Note that both of these functions are methods from the zoo class, which xts extends.</p>
<pre class="r"><code># Extract the core data of hayek
hayek_core &lt;- coredata(hayek)
# View the class of hayek_core
class(hayek_core) # data
# Extract the index of hayek
hayek_index &lt;- index(hayek)
# View the class of hayek_index
class(hayek_index) # date</code></pre>
<pre class="r"><code># Create dates increasing with 1 day
dates &lt;- as.Date(&quot;2016-01-01&quot;) + 0:4
# Create ts_a
ts_a &lt;- xts(x = 1:5, order.by = dates)
# Create ts_b
ts_b &lt;- xts(x = 1:5, order.by = as.POSIXct(dates))
# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_b)]
# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]</code></pre>
<p>It is often necessary to convert between classes when working with time series data in R. Conversion can be required for many reasons, but typically you’ll be looking to use a function that may not be time series aware or you may want to use a particular aspect of xts with something that doesn’t necessarily need to be a full time series.</p>
<p>Luckily, it is quite easy to convert back and forth using the standard as.* style functionality provided in R (for example, <code>as.POSIXct()</code> or <code>as.matrix()</code>). xts provides methods to convert all of the major objects you are likely to come across. Suitable native R types like matrix, data.frame, and ts are supported, as well as contributed ones such as <code>timeSeries</code>, <code>fts</code> and of course <code>zoo</code>. <code>as.xts()</code> is the workhorse function to do the conversions to xts, and similar functions will provide the reverse behavior.</p>
<pre class="r"><code># 1. Create dat by reading tmp_file
dat &lt;- read.csv(tmp_file)
# Convert dat into xts
xts(dat, order.by = as.Date(rownames(dat), &quot;%m/%d/%Y&quot;))
# 2. Read tmp_file using read.zoo
dat_zoo &lt;- read.zoo(tmp_file, index.column = 0, sep = &quot;,&quot;, format = &quot;%m/%d/%Y&quot;)
# Convert dat_zoo to xts
dat_xts &lt;- as.xts(dat_zoo)</code></pre>
<p>There are two main use cases for exporting xts objects. First, you may require an object to persist across sessions for use in later analysis. In this case, it is almost always best to use <code>saveRDS()</code> and <code>readRDS()</code> to serialize single R objects. Alternatively, you may find yourself needing to share the results of your analysis with others, often expecting the data to be consumed by processes unaware of both R and xts. Most of us would prefer not to think of this horrible fate for our data, but the real world mandates that we at least understand how this works. One of the best ways to write an xts object from R is to use the <code>zoo</code> function <code>write.zoo()</code>.</p>
<pre class="r"><code>data(&quot;sunspots&quot;)
library(xts)
library(zoo)
# Convert sunspots to xts using as.xts().
sunspots_xts &lt;- as.xts(sunspots)
# Get the temporary file name
tmp &lt;- tempfile()
# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = &quot;,&quot;, file = tmp)
# Read the tmp file. FUN = as.yearmon converts strings such as Jan 1749 into a proper time class
sun &lt;- read.zoo(tmp, sep = &quot;,&quot;, FUN = as.yearmon)
# Convert sun into xts. Save this as sun_xts
sun_xts &lt;- as.xts(sun)</code></pre>
<p>One of the most powerful aspects of working with time series in xts is the ability to quickly and efficiently specify dates and time ranges for subsetting. Date ranges can be extracted from <code>xts</code> objects by simply specifying the period(s) you want using special character strings in your subset.</p>
<pre class="r"><code>A[&quot;20090825&quot;]       # Aug 25, 2009
A[&quot;201203/201212&quot;]  # Mar to Dec 2012
A[&quot;/201601&quot;]        # Up to and including January 2016</code></pre>
<p>The most common time series data “in the wild” is daily. On occasion, you may find yourself working with intraday data, which contains both dates and times. In this case it is sometimes necessary to view only a subset of time for each day over multiple days. Using <code>xts</code>, you can slice days easily by using special notation in the <code>i =</code> argument to the single bracket extraction (i.e. <code>[i, j]</code>).</p>
<pre class="r"><code># Extract all data from irreg between 8AM and 10AM
morn_2010 &lt;- irreg[&quot;T08:00/T10:00&quot;]
# Extract the observations in morn_2010 for January 13th, 2010
morn_2010[&quot;2010-01-13&quot;]</code></pre>
<p>Sometimes you need to locate data by relative time. Something that is easier said than put into code. This is equivalent to requesting the head or tail of a series, but instead of using an absolute offset, you describe a relative position in time. A simple example would be something like the last 3 weeks of a series, or the first day of current month. Without a time aware object, this gets quite complicated very quickly. Luckily, xts has the necessary prerequisites built in for you to use with very little learning required. Using the <code>first()</code> and <code>last()</code> functions it is actually quite easy!</p>
<pre class="r"><code># Create lastweek using the last 1 week of temps
lastweek &lt;- last(temps, &quot;1 week&quot;)
# Print the last 2 observations in lastweek
last(lastweek, 2)
# Extract all but the first two days of lastweek
first(lastweek, &quot;-2 days&quot;)</code></pre>
<p><strong>Combining first and last</strong></p>
<pre class="r"><code># Extract the first three days of the second week of temps
first(last(first(temps, &quot;2 weeks&quot;), &quot;1 week&quot;), &quot;3 days&quot;)</code></pre>
<p>xts makes it easy to join data by column and row using a few different functions. All results will be correctly ordered in time, regardless of original frequencies or date class. One of the most important functions to accomplish this is <code>merge()</code>. It takes one or more series and joins them by column. It’s also possible to combine a series with a vector of dates. This is especially useful for normalizing observations to a fixed calendar.<code>merge()</code> takes three key arguments which we will emphasize here. First is the <code>...,</code> which lets you pass in an arbitrary number of objects to combine. The second argument is <code>join</code>, which specifies how to join the series - accepting arguments such as inner or left. This is similar to a relational database join, only here, the index is what we join on. The final argument for this exercise is <code>fill</code>. This keyword specifies what to do with the new values in a series if there is missingness introduced as a result of the merge.</p>
<pre class="r"><code># Basic argument use
merge(a, b, join = &quot;right&quot;, fill = 9999)</code></pre>
<p>Now that you have merged data by column, you will be happy to know it’s just as easy to add new rows to your data. <code>xts</code> provides its own S3 method to the base <code>rbind()</code> generic function. The <code>xts</code> rbind function is much simpler than <code>merge()</code>. The only argument that matters is <code>...</code>, which takes an arbitrary number of objects to bind. What is different is that rbind requires a time series, since we need to have timestamps for R to know where to insert new data.</p>
<pre class="r"><code># Row bind temps_june30 to temps, assign this to temps2
temps2 &lt;- rbind(temps_june30, temps)
# Row bind temps_july17 and temps_july18 to temps2, call this temps3
temps3 &lt;- rbind(temps_july17, temps_july18, temps2)</code></pre>
<p><strong>Fill missing values using last or previous observation</strong> As you’ve encountered already, it’s not uncommon to find yourself with missing values (i.e. NAs) in your time series. This may be the result of a data omission or some mathematical or merge operation you do on your data. you will use the most basic of these, <code>na.locf()</code>. This function takes the last observation carried forward approach. In most circumstances this is the correct thing to do. It both preserves the last known value and prevents any look-ahead bias from entering into the data. You can also apply next observation carried backward by setting <code>fromLast = TRUE</code>.</p>
<pre class="r"><code># Last obs. carried forward
na.locf(x)                
# Next obs. carried backward
na.locf(x, fromLast = TRUE) </code></pre>
<p>On occasion, a simple carry forward approach to missingness isn’t appropriate. It may be that a series is missing an observation due to a higher frequency sampling than the generating process. You might also encounter an observation that is in error, yet expected to be somewhere between the values of its neighboring observations. These are scenarios where interpolation is useful. <code>zoo</code> provides a powerful tool to do this. Based on simple linear interpolation between points, implemented with <code>na.approx()</code> the data points are approximated using the distance between the index values. In other words, the estimated value is linear in time.</p>
<pre class="r"><code># Interpolate NAs using linear approximation
na.approx(AirPass)</code></pre>
<p><strong>Combine a leading and lagging time series</strong> Both zoo and xts implement this behavior, and in fact extend it from the ts original in R. There are two major differences between xts and zoo implementations that you need to be aware of. One is the direction of the lag for a given k. The second is how missingness is handled afterwards.</p>
<p>For historical reasons in R, zoo uses a convention for the sign of k in which negative values indicate lags and positive values indicate leads. That is, in zoo lag(x, k = 1) will shift future values one step back in time. This is inconsistent with the vast majority of the time series literature, but is consistent with behavior in base R. xts implements the exact opposite, namely for a positive k, the series will shift the last value in time one period forward; this is consistent with intuition, but quite different than zoo.</p>
<pre class="r"><code># Create a leading object called lead_x
lead_x &lt;- lag(x, k = -1)
# Create a lagging object called lag_x
lag_x &lt;- lag(x, k = 1)
# Merge your three series together and assign to z
z &lt;- merge(lead_x, x, lag_x)</code></pre>
<p><strong>Calculate a difference of a series using diff().</strong> Another common operation on time series, typically on those that are non-stationary, is to take a difference of the series. The number of differences to take of a series is an application of recursively calling the difference function n times.</p>
<p>A simple way to view a single (or “first order”) difference is to see it as <code>x(t) - x(t-k)</code> where <code>k</code> is the number of lags to go back. Higher order differences are simply the reapplication of a difference to each prior result. In R, the difference operator for <code>xts</code> is made available using the <code>diff()</code> command. This function takes two arguments of note. The first is the lag, which is the number of periods, and the second is <code>differences</code>, which is the order of the difference (e.g. how many times <code>diff()</code> is called).</p>
<pre class="r"><code># These are the same
diff(x, differences = 2)
diff(diff(x))</code></pre>
<pre class="r"><code># Calculate the first difference of AirPass using lag and subtraction
diff_by_hand &lt;- AirPass - lag(AirPass)
# Use merge to compare the first parts of diff_by_hand and diff(AirPass)
merge(head(diff_by_hand), head(diff(AirPass)))
# Calculate the first order 12 month difference of AirPass
diff(AirPass, lag = 12, differences = 1)</code></pre>
<p>One of the benefits to working with time series objects is how easy it is to apply functions by time. The main function in <code>xts</code> to facilitate this is <code>endpoints()</code>. It takes a time series (or a vector of times) and returns the locations of the last observations in each interval. The argument on supports a variety of periods, including <code>&quot;years&quot;</code>, <code>&quot;quarters&quot;</code>, <code>&quot;months&quot;</code>, as well as intraday intervals such as <code>&quot;hours&quot;</code>, and <code>&quot;minutes&quot;</code>. What is returned is a vector starting with 0 and ending with the extent (last row) of your data.</p>
<pre class="r"><code># Locate the end of week in temps data
endpoints(temps, on = &quot;weeks&quot;)
# Locate the end of every second week
endpoints(temps, on = &quot;weeks&quot;, k = 2)</code></pre>
<p>Make use of the xts <code>split()</code> command to chunk your data by time. The <code>split()</code> function creates a list containing an element for each split. The f argument in <code>split()</code> is a character string describing the period to split by (i.e. <code>&quot;months&quot;</code>, <code>&quot;years&quot;</code>, etc.).</p>
<pre class="r"><code># Split temps by week
temps_weekly &lt;- split(temps, f = &quot;weeks&quot;)
# Create a list of weekly means, temps_avg
temps_avg &lt;- lapply(X = temps_weekly, FUN = mean)</code></pre>
<p><strong>Convert univariate series to OHLC data.</strong> You’ll convert from a univariate series into OHLC series, and then convert your final OHLC series back into a univariate series using the xts function <code>to.period()</code>. This function takes a time-series, <code>x</code>, and a string for the <code>period</code> (i.e. <code>months</code>, <code>days</code>, etc.), in addition to a number of other optional arguments.</p>
<pre class="r"><code>to.period(x,
          period = &quot;months&quot;, 
          k = 1, 
          indexAt, 
          name=NULL,
          OHLC = TRUE,
          ...)</code></pre>
<pre class="r"><code># Convert usd_eur to weekly and assign to usd_eur_weekly
usd_eur_weekly &lt;- to.period(usd_eur, period = &quot;weeks&quot;)
# Convert usd_eur to monthly and assign to usd_eur_monthly
usd_eur_monthly &lt;- to.period(usd_eur, period = &quot;months&quot;)
# Convert usd_eur to yearly univariate and assign to usd_eur_yearly, no OHLC bars
usd_eur_yearly &lt;- to.period(usd_eur, period = &quot;years&quot;, OHLC = FALSE)</code></pre>
<p>One common aggregation you may want to apply involves doing a calculation within the context of a period, but returning the interim results for each observation of the period. For example, you may want to calculate a running month-to-date cumulative sum of a series. This would be relevant when looking at monthly performance of a mutual fund you are interested in investing in. You’ll calculate the cumulative annual return using the edhec fund data from the last exercise. To do this, you’ll follow the <code>split()-lapply()-rbind()</code> pattern demonstrated below:</p>
<pre class="r"><code>x_split &lt;- split(x, f = &quot;months&quot;)
x_list &lt;- lapply(x_split, cummax)
x_list_rbind &lt;- do.call(rbind, x_list)</code></pre>
<p>Note the last call uses R’s somewhat strange <code>do.call(rbind, ...)</code> syntax, which allows you to pass a list to <code>rbind</code> instead of passing each object one at a time. This is a handy shortcut for your R toolkit.</p>
<pre class="r"><code># View the first three indexes of temps
index(temps)[1:3]
# Get the index class of temps
indexClass(temps)
# Get the timezone of temps
indexTZ(temps)
# Change the format of the time display
indexFormat(temps) &lt;- &quot;%b-%d-%Y&quot;</code></pre>
<p>One of the trickiest parts to working with time series in general is dealing with time zones. <code>xts</code> provides a simple way to leverage time zones on a per-series basis. While R provides time zone support in native classes <code>POSIXct</code> and <code>POSIXlt</code>, <code>xts</code> extends this power to the entire object, allowing you to have multiple time zones across various objects.</p>
<p>Some internal operation system functions require a time zone to do date math. If a time zone isn’t explicitly set, one is chosen for you! Be careful to always set a time zone in your environment to prevent errors when working with dates and times. <code>xts</code> provides the function <code>tzone()</code>, which allows you to extract or set time zones.</p>
<pre class="r"><code># Construct times_xts with tzone set to America/Chicago
times_xts &lt;- xts(1:10, order.by = times, tzone = &quot;America/Chicago&quot;)
# Change the time zone of times_xts to Asia/Hong_Kong
tzone(times_xts) &lt;- &quot;Asia/Hong_Kong&quot;</code></pre>
<p><code>xts</code> provides a handy tool to discover this regularity in your data by estimating the frequency of the observations - what we are referring to as periodicity - using the <a href="http://www.rdocumentation.org/packages/xts/versions/0.9-7/topics%20periodicity">periodicity()</a> command</p>
<pre class="r"><code># Calculate the periodicity of temps
periodicity(temps)
# Calculate the periodicity of edhec
periodicity(edhec)
# Convert edhec to yearly
edhec_yearly &lt;- to.yearly(edhec)
# Calculate the periodicity of edhec_yearly
periodicity(edhec_yearly)</code></pre>
<p>Often it is handy to know not just the range of your time series index, but also how many discrete irregular periods your time series data covers. You shouldn’t be surprised to learn that xts provides a set of functions to do just that!</p>
<p>If you have a time series, it is now easy to see how many days, weeks or years your data contains. To do so, simply use the function <code>ndays()</code> and its shortcut functions <code>nmonths()</code>, <code>nquarters()</code>, and so forth, making counting irregular periods easy.</p>
<pre class="r"><code># Count the months
nmonths(edhec)
# Count the quarters
nquarters(edhec)
# Count the years
nyears(edhec)</code></pre>
<p><code>xts</code> uses a very special attribute called <code>index</code> to provide time support to your objects. For performance and design reasons, the index is stored in a special way. This means that regardless of the class of your index (e.g. <code>Date</code> or <code>yearmon</code>) everything internally looks the same to <code>xts</code>. The raw index is actually a simple vector of fractional seconds since the UNIX epoch. Normally you want to access the times you stored. <code>index()</code> does this magically for you by using your <code>indexClass</code>. To get to the raw vector of the index, you can use <code>.index()</code>. Note the critical dot before the function name. More useful than extracting raw seconds is the ability to extract time components similar to the POSIXlt class, which closely mirrors the underlying POSIX internal compiled structure tm. This functionality is provided by a handful of commands such as <code>.indexday()</code>, <code>.indexmon()</code>, <code>.indexyear()</code>, and more.</p>
<pre class="r"><code># Explore underlying units of temps in two commands: .index() and .indexwday()
.index(temps)
.indexwday(temps)
# Create an index of weekend days using which()
index &lt;- which(.indexwday(temps) == 6 | .indexwday(temps) == 0)
# Select the index
temps[index]</code></pre>
<p>If you find that you have observations with identical timestamps, it might be useful to perturb or remove these times to allow for uniqueness. <code>xts</code> provides the function <code>make.index.unique()</code> for just this purpose. The eps argument, short for epsilon or small change, controls how much identical times should be perturbed, and <code>drop = TRUE</code> lets you just remove duplicate observations entirely.</p>
<p>On other ocassions you might find your timestamps a bit too precise. In these instances it might be better to round up to some fixed interval, for example an observation may occur at any point in an hour, but you want to record the latest as of the beginning of the next hour. For this situation, the <code>align.time()</code> command will do what you need, setting the n argument to the number of seconds you’d like to round to.</p>
<pre class="r"><code>make.index.unique(x, eps = 1e-4)  # Perturb
make.index.unique(x, drop = TRUE) # Drop duplicates
align.time(x, n = 60) # Round to the minute</code></pre>
<pre class="r"><code># Make z have unique timestamps
z_unique &lt;- make.index.unique(z, eps = 1e-4)
# Remove duplicate times in z
z_dup &lt;- make.index.unique(z, drop = TRUE)
# Round observations in z to the next hour
z_round &lt;- align.time(z, n = 3600)</code></pre>
</div>
</div>
<div id="basic-time-series-plot" class="section level1">
<h1>Basic time series plot</h1>
<p>While simple commands such as <code>print()</code>, <code>length()</code>, <code>head()</code>, and <code>tail()</code> provide crucial information about your time series data, another very useful way to explore any data is to generate a plot.</p>
<pre class="r"><code># Plot the Nile data with xlab and ylab arguments
plot(Nile, xlab = &quot;Year&quot;, ylab = &quot;River Volume (1e9 m^{3})&quot;)
# Plot the Nile data with xlab, ylab, main, and type arguments
plot(Nile, xlab = &quot;Year&quot;, ylab = &quot;River Volume (1e9 m^{3})&quot;, main = &quot;Annual River Nile Volume at Aswan, 1871-1970&quot;, type =&quot;b&quot;)</code></pre>
<p><img src="images/basicplot1.png" width="50%" /><img src="images/basicplot2.png" width="50%" /></p>
<p>The <code>start()</code> and <code>end()</code> functions return the time index of the first and last observations, respectively. The <code>time()</code> function calculates a vector of time indices, with one element for each time index on which the series was observed.</p>
<p>The <code>deltat()</code> function returns the fixed time interval between observations and the <code>frequency()</code> function returns the number of observations per unit time. Finally, the <code>cycle()</code> function returns the position in the cycle of each observation.</p>
<p>The function <code>ts()</code> can be applied to create time series objects. A time series object is a vector (univariate) or matrix (multivariate) with additional attributes, including time indices for each observation, the sampling frequency and time increment between observations, and the cycle length for periodic data. Such objects are of the <code>ts</code> class, and represent data that has been observed at (approximately) equally spaced time points.</p>
<pre class="r"><code># Use print() and plot() to view data_vector
plot(data_vector)
# Convert data_vector to a ts object with start = 2004 and frequency = 4
time_series &lt;- ts(data_vector, start = 2004, frequency = 4)
# Use print() and plot() to view time_series
plot(time_series)</code></pre>
<p><img src="images/create%20a%20time%20series1.png" width="50%" /><img src="images/create%20a%20time%20series2.png" width="50%" /></p>
<p>When you use datasets from others, such as those included in an R package, you can check whether they are ts objects using the <code>is.ts()</code> command. The result of the test is either <code>TRUE</code> when the data is of the ts class, or <code>FALSE</code> if it is not.</p>
<p>For time series exhibiting seasonal trends, seasonal differencing can be applied to remove these periodic patterns. For example, monthly data may exhibit a strong twelve month pattern. In such situations, changes in behavior from year to year may be of more interest than changes from month to month, which may largely follow the overall seasonal pattern.</p>
<p>The function <code>diff(..., lag = s)</code> will calculate the lag <code>s</code> difference or length <code>s</code> seasonal change series. For monthly or quarterly data, an appropriate value of <code>s</code> would be 12 or 4, respectively. The <code>diff()</code> function has <code>lag = 1</code> as its default for first differencing. Similar to before, a seasonally differenced series will have <code>s</code> fewer observations than the original series.</p>
<pre class="r"><code># Generate a diff of x with lag = 4. Save this to dx
dx &lt;- diff(x, lag = 4)
# Plot dx
ts.plot(dx)</code></pre>
<p><img src="images/difference1.png" width="50%" /><img src="images/difference2.png" width="50%" /></p>
<div id="simulate-the-white-noise-model" class="section level2">
<h2>Simulate the white noise model</h2>
<p>The white noise (WN) model is a basic time series model. It is also a basis for the more elaborate models we will consider. We will focus on the simplest form of WN, independent and identically distributed data. The <code>arima.sim()</code> function can be used to simulate data from a variety of time series models. ARIMA is an abbreviation for the autoregressive integrated moving average class of models. An <code>ARIMA(p, d, q)</code> model has three parts, the autoregressive order <code>p</code>, the order of integration (or differencing) <code>d</code>, and the moving average order <code>q</code>. For now we note that the <code>ARIMA(0, 0, 0)</code> model, i.e., with all of these components zero, is simply the WN model.</p>
<pre class="r"><code># Simulate a WN model with list(order = c(0, 0, 0))
white_noise &lt;- arima.sim(model = list(order = c(0, 0, 0)), n = 100)
# Plot your white_noise data
ts.plot(white_noise)
# Simulate from the WN model with: mean = 100, sd = 10
white_noise_2 &lt;- arima.sim(model = list(order = c(0, 0, 0)), n = 100, mean = 100, sd = 10)
# Plot your white_noise_2 data
ts.plot(white_noise_2)</code></pre>
<p><img src="images/white_noise1.png" width="50%" /><img src="images/white_noise2.png" width="50%" /></p>
</div>
<div id="simulate-the-random-walk-model" class="section level2">
<h2>Simulate the random walk model</h2>
<p>The random walk (RW) model is also a basic time series model. It is the cumulative sum (or integration) of a mean zero white noise (WN) series, such that the first difference series of a RW is a WN series. Note for reference that the RW model is an <code>ARIMA(0, 1, 0)</code> model, in which the middle entry of 1 indicates that the model’s order of integration is 1. The <code>arima.sim()</code> function can be used to simulate data from the RW by including the <code>model = list(order = c(0, 1, 0))</code> argument. We also need to specify a series length <code>n</code>. Finally, you can specify a <code>sd</code> for the series (increments), where the default value is 1.</p>
<pre class="r"><code># Generate a RW model using arima.sim
random_walk &lt;- arima.sim(model = list(order = c(0, 1, 0)), n = 100)
# Plot random_walk
ts.plot(random_walk)
# Calculate the first difference series
random_walk_diff &lt;- diff(random_walk)
# Plot random_walk_diff
ts.plot(random_walk_diff)</code></pre>
<p><img src="images/randomwalk1.png" width="50%" /><img src="images/randomwalk2.png" width="50%" /></p>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p><a href="https://www.datacamp.com/home">DataCamp</a></p>
<p><a href="https://www.zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/">Tips for working with images</a></p>
<p><a href="http://r4ds.had.co.nz/tidy-data.html">R for Data Science</a></p>
<p>…..</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
